"""Explainability (XAI) â€” AÃ§Ä±klanabilir Yapay Zeka ModÃ¼lÃ¼

Mevcut reflection.py + risk_analyzer.py'Ä± gÃ¼Ã§lendirir:
- Karar aÃ§Ä±klama zinciri (reasoning chain)
- FaktÃ¶r aÄŸÄ±rlÄ±klandÄ±rma
- KarÅŸÄ±-olgusal analiz (counterfactual)
- GÃ¼ven skoru daÄŸÄ±lÄ±mÄ±
- KullanÄ±cÄ± dostu Ã¶zet oluÅŸturma
"""

import json
import re
from typing import Optional, List, Dict, Any
from pathlib import Path
from datetime import datetime
import structlog

logger = structlog.get_logger()


class DecisionExplainer:
    """AI kararlarÄ±nÄ± aÃ§Ä±klayan modÃ¼l."""

    # â”€â”€ FaktÃ¶r aÄŸÄ±rlÄ±klarÄ± â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    FACTOR_WEIGHTS = {
        "veri_kalitesi":    0.20,
        "model_gÃ¼veni":     0.25,
        "geÃ§miÅŸ_doÄŸruluk": 0.15,
        "risk_seviyesi":    0.20,
        "baÄŸlam_uyumu":     0.10,
        "zaman_tutarlÄ±lÄ±ÄŸÄ±": 0.10,
    }

    RISK_KEYWORDS = {
        "yÃ¼ksek": ["fire", "zarar", "kayÄ±p", "tehlike", "kriz", "acil", "dÃ¼ÅŸÃ¼ÅŸ"],
        "orta":   ["risk", "dikkat", "kontrol", "izleme", "sapma"],
        "dÃ¼ÅŸÃ¼k":  ["normal", "stabil", "artÄ±ÅŸ", "olumlu", "iyileÅŸme"],
    }

    def explain_decision(
        self,
        query: str,
        response: str,
        confidence: float = 0.0,
        context_data: Optional[Dict] = None,
        module_source: str = "unknown",
    ) -> Dict:
        """Bir AI kararÄ±nÄ±n tam aÃ§Ä±klamasÄ±nÄ± Ã¼ret.

        Returns:
            {
                "summary": "...",
                "confidence": 0.82,
                "factors": [...],
                "reasoning_chain": [...],
                "risk_assessment": {...},
                "counterfactual": "...",
                "recommendations": [...],
            }
        """
        ctx = context_data or {}

        # 1. FaktÃ¶r analizi
        factors = self._analyze_factors(query, response, confidence, ctx)

        # 2. AkÄ±l yÃ¼rÃ¼tme zinciri
        chain = self._build_reasoning_chain(query, response, module_source, ctx)

        # 3. Risk deÄŸerlendirmesi
        risk = self._assess_risk(query, response)

        # 4. KarÅŸÄ±-olgusal
        counterfactual = self._generate_counterfactual(query, factors, risk)

        # 5. Ã–neriler
        recommendations = self._generate_recommendations(factors, risk, confidence)

        # 6. Toplam gÃ¼ven
        weighted_conf = self._calculate_weighted_confidence(factors)

        # 7. Ã–zet
        summary = self._build_summary(query, module_source, weighted_conf, risk)

        return {
            "summary": summary,
            "confidence": round(weighted_conf, 3),
            "confidence_label": self._confidence_label(weighted_conf),
            "factors": factors,
            "reasoning_chain": chain,
            "risk_assessment": risk,
            "counterfactual": counterfactual,
            "recommendations": recommendations,
            "module_source": module_source,
            "timestamp": datetime.now().isoformat(),
        }

    # â”€â”€ FaktÃ¶r Analizi â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

    def _analyze_factors(
        self, query: str, response: str, confidence: float, ctx: Dict
    ) -> List[Dict]:
        """Her karar faktÃ¶rÃ¼nÃ¼ ayrÄ± ayrÄ± deÄŸerlendir."""
        factors = []

        # 1. Veri kalitesi
        data_quality = ctx.get("data_quality", 0.7)
        factors.append({
            "name": "Veri Kalitesi",
            "score": round(data_quality, 2),
            "weight": self.FACTOR_WEIGHTS["veri_kalitesi"],
            "explanation": self._data_quality_text(data_quality),
        })

        # 2. Model gÃ¼veni
        model_conf = confidence if confidence > 0 else 0.5
        factors.append({
            "name": "Model GÃ¼veni",
            "score": round(model_conf, 2),
            "weight": self.FACTOR_WEIGHTS["model_gÃ¼veni"],
            "explanation": f"LLM yanÄ±t gÃ¼veni: {model_conf:.0%}",
        })

        # 3. GeÃ§miÅŸ doÄŸruluk
        hist_accuracy = ctx.get("historical_accuracy", 0.75)
        factors.append({
            "name": "GeÃ§miÅŸ DoÄŸruluk",
            "score": round(hist_accuracy, 2),
            "weight": self.FACTOR_WEIGHTS["geÃ§miÅŸ_doÄŸruluk"],
            "explanation": f"Benzer sorulardaki geÃ§miÅŸ doÄŸruluk oranÄ±: {hist_accuracy:.0%}",
        })

        # 4. Risk seviyesi
        risk_score = self._risk_score(query, response)
        factors.append({
            "name": "Risk DeÄŸerlendirmesi",
            "score": round(1.0 - risk_score, 2),  # dÃ¼ÅŸÃ¼k risk = yÃ¼ksek skor
            "weight": self.FACTOR_WEIGHTS["risk_seviyesi"],
            "explanation": f"Risk seviyesi: {risk_score:.0%} â€” "
                          + ("DÃ¼ÅŸÃ¼k" if risk_score < 0.3 else "Orta" if risk_score < 0.6 else "YÃ¼ksek"),
        })

        # 5. BaÄŸlam uyumu
        context_match = ctx.get("context_relevance", 0.7)
        factors.append({
            "name": "BaÄŸlam Uyumu",
            "score": round(context_match, 2),
            "weight": self.FACTOR_WEIGHTS["baÄŸlam_uyumu"],
            "explanation": f"Soru-yanÄ±t baÄŸlam uyumu: {context_match:.0%}",
        })

        # 6. Zaman tutarlÄ±lÄ±ÄŸÄ±
        time_cons = ctx.get("time_consistency", 0.8)
        factors.append({
            "name": "Zaman TutarlÄ±lÄ±ÄŸÄ±",
            "score": round(time_cons, 2),
            "weight": self.FACTOR_WEIGHTS["zaman_tutarlÄ±lÄ±ÄŸÄ±"],
            "explanation": f"Ã–nceki yanÄ±tlarla tutarlÄ±lÄ±k: {time_cons:.0%}",
        })

        return factors

    def _data_quality_text(self, score: float) -> str:
        if score >= 0.8:
            return "YÃ¼ksek kaliteli, gÃ¼ncel veriler kullanÄ±ldÄ±"
        if score >= 0.5:
            return "Orta kaliteli veriler â€” bazÄ± eksiklikler olabilir"
        return "DÃ¼ÅŸÃ¼k kaliteli/eksik veriler â€” sonuÃ§lar dikkatle deÄŸerlendirilmeli"

    # â”€â”€ AkÄ±l YÃ¼rÃ¼tme Zinciri â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

    def _build_reasoning_chain(
        self, query: str, response: str, module: str, ctx: Dict
    ) -> List[Dict]:
        """KararÄ±n adÄ±m adÄ±m aÃ§Ä±klamasÄ±."""
        chain = []

        # AdÄ±m 1: Sorgu analizi
        chain.append({
            "step": 1,
            "action": "Sorgu Analizi",
            "detail": f"KullanÄ±cÄ± sorusu alÄ±ndÄ± ({len(query)} karakter). "
                     f"ModÃ¼l: {module}",
        })

        # AdÄ±m 2: Veri toplama
        sources = ctx.get("sources", [])
        chain.append({
            "step": 2,
            "action": "Veri Toplama",
            "detail": f"{len(sources)} veri kaynaÄŸÄ±ndan bilgi toplandÄ±"
                     if sources else "Ä°Ã§ bilgi tabanÄ± ve genel model bilgisi kullanÄ±ldÄ±",
        })

        # AdÄ±m 3: Analiz
        chain.append({
            "step": 3,
            "action": "Analiz & Ä°ÅŸleme",
            "detail": f"Sorgu {module} modÃ¼lÃ¼ ile iÅŸlendi. "
                     f"YanÄ±t uzunluÄŸu: {len(response)} karakter.",
        })

        # AdÄ±m 4: Risk kontrolÃ¼
        risk = self._risk_score(query, response)
        chain.append({
            "step": 4,
            "action": "Risk KontrolÃ¼",
            "detail": f"Risk seviyesi hesaplandÄ±: {risk:.0%}. "
                     + ("Onay gerekmedi." if risk < 0.5 else "Ä°nsan onayÄ± gerekebilir."),
        })

        # AdÄ±m 5: YanÄ±t oluÅŸturma
        chain.append({
            "step": 5,
            "action": "YanÄ±t OluÅŸturma",
            "detail": "TÃ¼m faktÃ¶rler deÄŸerlendirilerek nihai yanÄ±t oluÅŸturuldu.",
        })

        return chain

    # â”€â”€ Risk Skoru â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

    def _risk_score(self, query: str, response: str) -> float:
        """Basit kural bazlÄ± risk skoru (0-1)."""
        text = (query + " " + response).lower()
        high_count = sum(1 for k in self.RISK_KEYWORDS["yÃ¼ksek"] if k in text)
        mid_count  = sum(1 for k in self.RISK_KEYWORDS["orta"]   if k in text)
        low_count  = sum(1 for k in self.RISK_KEYWORDS["dÃ¼ÅŸÃ¼k"]  if k in text)

        score = (high_count * 0.3 + mid_count * 0.1 - low_count * 0.05)
        return max(0.0, min(1.0, score))

    def _assess_risk(self, query: str, response: str) -> Dict:
        score = self._risk_score(query, response)
        if score < 0.3:
            level, color = "DÃ¼ÅŸÃ¼k", "green"
        elif score < 0.6:
            level, color = "Orta", "yellow"
        else:
            level, color = "YÃ¼ksek", "red"

        return {
            "score": round(score, 2),
            "level": level,
            "color": color,
            "needs_approval": score >= 0.6,
        }

    # â”€â”€ KarÅŸÄ±-Olgusal â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

    def _generate_counterfactual(
        self, query: str, factors: List[Dict], risk: Dict
    ) -> str:
        """FarklÄ± koÅŸullarda sonucun nasÄ±l deÄŸiÅŸeceÄŸini aÃ§Ä±kla."""
        weakest = min(factors, key=lambda f: f["score"])
        strongest = max(factors, key=lambda f: f["score"])

        parts = []
        if weakest["score"] < 0.5:
            parts.append(
                f"EÄŸer '{weakest['name']}' faktÃ¶rÃ¼ daha yÃ¼ksek olsaydÄ± "
                f"(mevcut: {weakest['score']:.0%}), gÃ¼ven skoru Ã¶nemli Ã¶lÃ§Ã¼de artardÄ±."
            )
        if risk["score"] > 0.5:
            parts.append(
                "Sorgu daha az riskli iÃ§erik barÄ±ndÄ±rsaydÄ±, "
                "otomatik onay verilebilirdi."
            )
        if not parts:
            parts.append(
                f"En gÃ¼Ã§lÃ¼ faktÃ¶r '{strongest['name']}' ({strongest['score']:.0%}). "
                f"TÃ¼m faktÃ¶rler yeterli seviyede."
            )

        return " ".join(parts)

    # â”€â”€ Ã–neriler â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

    def _generate_recommendations(
        self, factors: List[Dict], risk: Dict, confidence: float
    ) -> List[str]:
        recs = []
        for f in factors:
            if f["score"] < 0.5:
                recs.append(f"âš ï¸ {f['name']} dÃ¼ÅŸÃ¼k ({f['score']:.0%}) â€” iyileÅŸtirme Ã¶nerilir")

        if risk["needs_approval"]:
            recs.append("ğŸ”’ YÃ¼ksek riskli karar â€” insan onayÄ± gerekli")

        if confidence < 0.5:
            recs.append("ğŸ“Š Model gÃ¼veni dÃ¼ÅŸÃ¼k â€” ek veri veya alternatif model deneyin")

        if not recs:
            recs.append("âœ… TÃ¼m faktÃ¶rler kabul edilebilir seviyede")

        return recs

    # â”€â”€ GÃ¼ven Hesaplama â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

    def _calculate_weighted_confidence(self, factors: List[Dict]) -> float:
        total = sum(f["score"] * f["weight"] for f in factors)
        return max(0.0, min(1.0, total))

    def _confidence_label(self, conf: float) -> str:
        if conf >= 0.8:
            return "YÃ¼ksek"
        if conf >= 0.6:
            return "Orta"
        if conf >= 0.4:
            return "DÃ¼ÅŸÃ¼k"
        return "Ã‡ok DÃ¼ÅŸÃ¼k"

    def _build_summary(
        self, query: str, module: str, confidence: float, risk: Dict
    ) -> str:
        return (
            f"Bu yanÄ±t {module} modÃ¼lÃ¼ tarafÄ±ndan Ã¼retilmiÅŸtir. "
            f"Toplam gÃ¼ven skoru: {confidence:.0%} ({self._confidence_label(confidence)}). "
            f"Risk seviyesi: {risk['level']}."
        )

    # â”€â”€ Toplu AÃ§Ä±klama â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

    def explain_batch(self, decisions: List[Dict]) -> Dict:
        """Birden fazla kararÄ± toplu olarak aÃ§Ä±kla."""
        results = []
        for d in decisions:
            exp = self.explain_decision(
                query=d.get("query", ""),
                response=d.get("response", ""),
                confidence=d.get("confidence", 0.0),
                context_data=d.get("context_data"),
                module_source=d.get("module_source", "unknown"),
            )
            results.append(exp)

        avg_conf = sum(r["confidence"] for r in results) / len(results) if results else 0
        risk_dist = {"DÃ¼ÅŸÃ¼k": 0, "Orta": 0, "YÃ¼ksek": 0}
        for r in results:
            level = r["risk_assessment"]["level"]
            risk_dist[level] += 1

        return {
            "total": len(results),
            "average_confidence": round(avg_conf, 3),
            "risk_distribution": risk_dist,
            "explanations": results,
        }

    def get_dashboard(self) -> Dict:
        """XAI modÃ¼l durumu."""
        return {
            "module": "Explainability (XAI)",
            "version": "1.0.0",
            "factors": list(self.FACTOR_WEIGHTS.keys()),
            "factor_count": len(self.FACTOR_WEIGHTS),
            "capabilities": [
                "FaktÃ¶r aÄŸÄ±rlÄ±klandÄ±rma",
                "AkÄ±l yÃ¼rÃ¼tme zinciri",
                "Risk deÄŸerlendirmesi",
                "KarÅŸÄ±-olgusal analiz",
                "Toplu aÃ§Ä±klama",
                "GÃ¼ven skoru hesaplama",
            ],
        }


# â”€â”€ Singleton â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
decision_explainer = DecisionExplainer()
