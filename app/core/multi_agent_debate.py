"""Multi-Agent Debate System v1.0 â€” Ã‡ok Perspektifli TartÄ±ÅŸma Motoru

Mevcut agent_pipeline'Ä±n ÃœSTÃœNE inÅŸa edilen ileri seviye tartÄ±ÅŸma sistemi.
Sequential pipeline yerine paralel perspektif ajanlarÄ± bir konuyu FARKLI
aÃ§Ä±lardan analiz eder, birbirlerinin argÃ¼manlarÄ±nÄ± Ã§Ã¼rÃ¼tÃ¼r/destekler,
ve sentez ajanÄ± final kararÄ± oluÅŸturur.

Mimari:
  1. PerspectiveAgent'lar â†’ BaÄŸÄ±msÄ±z analiz (paralel)
  2. DebateRound'lar â†’ ArgÃ¼man/KarÅŸÄ±-argÃ¼man (round-robin)
  3. ConsensusDetector â†’ UzlaÅŸma/ayrÄ±ÅŸma tespiti
  4. SynthesisEngine â†’ Final sentez + confidence boost/penalty
  5. DebateTracker â†’ GeÃ§miÅŸ tartÄ±ÅŸma performans analizi

Perspektif AjanlarÄ±:
  - DevilsAdvocateAgent â†’ KarÅŸÄ±t gÃ¶rÃ¼ÅŸ, zayÄ±f noktalar
  - RiskAnalystAgent    â†’ Risk/fÄ±rsat deÄŸerlendirmesi
  - OptimistAgent       â†’ En iyi senaryo, bÃ¼yÃ¼me fÄ±rsatlarÄ±
  - DomainExpertAgent   â†’ SektÃ¶r-spesifik teknik analiz
  - EthicistAgent       â†’ Etik, sÃ¼rdÃ¼rÃ¼lebilirlik, sosyal etki
  - PragmatistAgent     â†’ Uygulama fizibilitesi, kaynak/zaman

v4.7.0 â€” CompanyAI Enterprise
"""

from __future__ import annotations

import hashlib
import time
import uuid
from collections import defaultdict
from dataclasses import dataclass, field
from datetime import datetime, timezone
from enum import Enum
from typing import Any, Dict, List, Optional, Tuple

import structlog

logger = structlog.get_logger(__name__)


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# SABÄ°TLER
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

MAX_DEBATE_ROUNDS = 3              # Maksimum tartÄ±ÅŸma turu
MIN_PERSPECTIVES = 3               # Minimum perspektif sayÄ±sÄ±
MAX_PERSPECTIVES = 6               # Maksimum perspektif sayÄ±sÄ±
CONSENSUS_THRESHOLD = 0.70         # UzlaÅŸma eÅŸiÄŸi (0-1)
STRONG_CONSENSUS_THRESHOLD = 0.85  # GÃ¼Ã§lÃ¼ uzlaÅŸma
CONFIDENCE_BOOST_ON_CONSENSUS = 8  # UzlaÅŸmada confidence artÄ±ÅŸÄ±
CONFIDENCE_PENALTY_ON_SPLIT = 5    # AyrÄ±ÅŸmada confidence dÃ¼ÅŸÃ¼ÅŸÃ¼
MAX_DEBATE_HISTORY = 200           # Saklanan tartÄ±ÅŸma sayÄ±sÄ±
DEBATE_TRIGGER_KEYWORDS = [
    "analiz", "deÄŸerlendir", "karÅŸÄ±laÅŸtÄ±r", "risk", "strateji",
    "yatÄ±rÄ±m", "karar", "seÃ§enek", "alternatif", "fÄ±rsat",
    "tehdit", "etki", "projeksiyon", "tahmin", "Ã¶neri",
    "avantaj", "dezavantaj", "swot", "maliyet", "fayda",
]
DEBATE_TRIGGER_MODES = ["Ãœst DÃ¼zey Analiz", "CEO Raporu", "Risk Analizi"]
DEBATE_TRIGGER_MIN_LENGTH = 40  # KÄ±sa sorular debate'e girmez


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ENUM & VERÄ° YAPILARI
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

class PerspectiveType(str, Enum):
    DEVILS_ADVOCATE = "devils_advocate"
    RISK_ANALYST = "risk_analyst"
    OPTIMIST = "optimist"
    DOMAIN_EXPERT = "domain_expert"
    ETHICIST = "ethicist"
    PRAGMATIST = "pragmatist"


class DebateOutcome(str, Enum):
    CONSENSUS = "consensus"            # TÃ¼m perspektifler uyumlu
    STRONG_CONSENSUS = "strong_consensus"  # Ã‡ok gÃ¼Ã§lÃ¼ uyum
    MAJORITY = "majority"              # Ã‡oÄŸunluk uyumlu
    SPLIT = "split"                    # BÃ¶lÃ¼nmÃ¼ÅŸ gÃ¶rÃ¼ÅŸler
    DEADLOCK = "deadlock"              # Ã‡Ã¶zÃ¼msÃ¼z ayrÄ±ÅŸma


class ArgumentStrength(str, Enum):
    STRONG = "strong"
    MODERATE = "moderate"
    WEAK = "weak"


def _utcnow_str() -> str:
    return datetime.now(timezone.utc).isoformat()


@dataclass
class Argument:
    """Bir perspektif ajanÄ±nÄ±n tek bir argÃ¼manÄ±."""
    perspective: PerspectiveType
    claim: str
    evidence: List[str] = field(default_factory=list)
    strength: ArgumentStrength = ArgumentStrength.MODERATE
    confidence: float = 0.5
    supports: List[str] = field(default_factory=list)   # DesteklediÄŸi diÄŸer perspektif claim'leri
    counters: List[str] = field(default_factory=list)    # Ã‡Ã¼rÃ¼ttÃ¼ÄŸÃ¼ diÄŸer perspektif claim'leri
    round_number: int = 1

    def to_dict(self) -> dict:
        return {
            "perspective": self.perspective.value,
            "claim": self.claim,
            "evidence": self.evidence,
            "strength": self.strength.value,
            "confidence": self.confidence,
            "supports_count": len(self.supports),
            "counters_count": len(self.counters),
            "round": self.round_number,
        }


@dataclass
class PerspectiveAnalysis:
    """Bir perspektif ajanÄ±nÄ±n tam analizi."""
    perspective: PerspectiveType
    label: str
    summary: str
    arguments: List[Argument] = field(default_factory=list)
    recommendation: str = ""
    risk_level: float = 0.0      # 0-1, bu perspektifin gÃ¶rdÃ¼ÄŸÃ¼ risk
    opportunity_level: float = 0.0  # 0-1, bu perspektifin gÃ¶rdÃ¼ÄŸÃ¼ fÄ±rsat
    confidence: float = 0.5
    generation_time_ms: float = 0.0

    def to_dict(self) -> dict:
        return {
            "perspective": self.perspective.value,
            "label": self.label,
            "summary": self.summary,
            "arguments": [a.to_dict() for a in self.arguments],
            "recommendation": self.recommendation,
            "risk_level": round(self.risk_level, 2),
            "opportunity_level": round(self.opportunity_level, 2),
            "confidence": round(self.confidence, 2),
            "generation_time_ms": round(self.generation_time_ms, 1),
        }


@dataclass
class DebateRound:
    """Bir tartÄ±ÅŸma turu â€” tÃ¼m perspektiflerin argÃ¼manlarÄ±."""
    round_number: int
    arguments: List[Argument] = field(default_factory=list)
    agreements: List[Tuple[str, str]] = field(default_factory=list)  # (perspektif1, perspektif2)
    disagreements: List[Tuple[str, str, str]] = field(default_factory=list)  # (p1, p2, konu)

    def to_dict(self) -> dict:
        return {
            "round": self.round_number,
            "arguments_count": len(self.arguments),
            "arguments": [a.to_dict() for a in self.arguments],
            "agreements": len(self.agreements),
            "disagreements": len(self.disagreements),
        }


@dataclass
class ConsensusResult:
    """UzlaÅŸma analizi sonucu."""
    outcome: DebateOutcome
    consensus_score: float           # 0-1
    agreed_points: List[str] = field(default_factory=list)
    disputed_points: List[str] = field(default_factory=list)
    minority_views: List[str] = field(default_factory=list)
    risk_warnings: List[str] = field(default_factory=list)
    confidence_adjustment: float = 0.0

    def to_dict(self) -> dict:
        return {
            "outcome": self.outcome.value,
            "consensus_score": round(self.consensus_score, 3),
            "agreed_points": self.agreed_points,
            "disputed_points": self.disputed_points,
            "minority_views": self.minority_views,
            "risk_warnings": self.risk_warnings,
            "confidence_adjustment": self.confidence_adjustment,
        }


@dataclass
class DebateResult:
    """Tam tartÄ±ÅŸma sonucu."""
    debate_id: str
    question: str
    department: str
    mode: str
    timestamp: str
    perspectives_used: List[PerspectiveType] = field(default_factory=list)
    analyses: List[PerspectiveAnalysis] = field(default_factory=list)
    rounds: List[DebateRound] = field(default_factory=list)
    consensus: Optional[ConsensusResult] = None
    synthesis: str = ""
    final_recommendation: str = ""
    confidence_before: float = 0.0
    confidence_after: float = 0.0
    total_time_ms: float = 0.0
    triggered_by: str = "auto"

    def to_dict(self) -> dict:
        return {
            "debate_id": self.debate_id,
            "question": self.question[:200],
            "department": self.department,
            "mode": self.mode,
            "timestamp": self.timestamp,
            "perspectives": [p.value for p in self.perspectives_used],
            "perspectives_count": len(self.perspectives_used),
            "analyses": [a.to_dict() for a in self.analyses],
            "rounds_count": len(self.rounds),
            "rounds": [r.to_dict() for r in self.rounds],
            "consensus": self.consensus.to_dict() if self.consensus else None,
            "synthesis": self.synthesis,
            "final_recommendation": self.final_recommendation,
            "confidence_before": round(self.confidence_before, 1),
            "confidence_after": round(self.confidence_after, 1),
            "confidence_delta": round(self.confidence_after - self.confidence_before, 1),
            "total_time_ms": round(self.total_time_ms, 1),
            "triggered_by": self.triggered_by,
        }


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# PERSPEKTÄ°F TANIMLARI â€” Her ajana Ã¶zel bakÄ±ÅŸ aÃ§Ä±sÄ±
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

PERSPECTIVE_CONFIGS: Dict[PerspectiveType, Dict[str, Any]] = {
    PerspectiveType.DEVILS_ADVOCATE: {
        "label": "Åžeytan'Ä±n AvukatÄ±",
        "description": "KarÅŸÄ±t gÃ¶rÃ¼ÅŸ Ã¼retir, zayÄ±f noktalarÄ± bulur",
        "system_prompt": (
            "Sen bir Åžeytan'Ä±n AvukatÄ± analiz ajanÄ±sÄ±n. GÃ¶revin:\n"
            "1. Ã–nerilen Ã§Ã¶zÃ¼mÃ¼n/analizin ZAYÄ±F noktalarÄ±nÄ± bul\n"
            "2. GÃ¶zden kaÃ§abilecek RÄ°SKLERÄ° tespit et\n"
            "3. VarsayÄ±mlarÄ± SORGULA â€” hangi varsayÄ±mlar yanlÄ±ÅŸsa sonuÃ§ deÄŸiÅŸir?\n"
            "4. Alternatif senaryolarÄ± dÃ¼ÅŸÃ¼n â€” tam tersi olursa ne olur?\n"
            "5. Bias (Ã¶nyargÄ±) tespiti yap â€” karar vericiler neyi gÃ¶rmezden geliyor?\n"
            "\nHer zaman yapÄ±cÄ± eleÅŸtiri yap. Sadece sorun bulma deÄŸil, Ã§Ã¶zÃ¼m de Ã¶ner."
        ),
        "focus_areas": ["zayÄ±f_nokta", "varsayÄ±m", "Ã¶nyargÄ±", "alternatif_senaryo"],
        "risk_weight": 0.8,
        "opportunity_weight": 0.2,
    },
    PerspectiveType.RISK_ANALYST: {
        "label": "Risk Analisti",
        "description": "Risk/fÄ±rsat deÄŸerlendirmesi, olasÄ±lÄ±k analizi",
        "system_prompt": (
            "Sen bir Risk Analisti ajanÄ±sÄ±n. GÃ¶revin:\n"
            "1. TÃ¼m riskleri TANIMLA ve kategorize et (operasyonel, finansal, stratejik, uyumluluk)\n"
            "2. Her risk iÃ§in OLASILIK (dÃ¼ÅŸÃ¼k/orta/yÃ¼ksek) ve ETKÄ° (dÃ¼ÅŸÃ¼k/orta/yÃ¼ksek) belirle\n"
            "3. Risk azaltma STRATEJÄ°LERÄ° Ã¶ner â€” her risk iÃ§in en az 1 azaltma planÄ±\n"
            "4. FÄ±rsatlarÄ± da belirle â€” risk almak ne kazandÄ±rabilir?\n"
            "5. Risk/Ã¶dÃ¼l DENGESÄ°NÄ° deÄŸerlendir\n"
            "\nSayÄ±sal risk skorlarÄ± kullan (1-10) ve Ã¶ncelik sÄ±ralamasÄ± yap."
        ),
        "focus_areas": ["risk_tanÄ±mlama", "olasÄ±lÄ±k", "etki", "azaltma", "risk_Ã¶dÃ¼l"],
        "risk_weight": 0.7,
        "opportunity_weight": 0.3,
    },
    PerspectiveType.OPTIMIST: {
        "label": "FÄ±rsatÃ§Ä± Optimist",
        "description": "En iyi senaryolar, bÃ¼yÃ¼me fÄ±rsatlarÄ±, potansiyel kazanÃ§lar",
        "system_prompt": (
            "Sen bir Stratejik Optimist ajanÄ±sÄ±n. GÃ¶revin:\n"
            "1. En Ä°YÄ° SENARYO'yu detaylÄ± analiz et â€” her ÅŸey yolunda giderse ne olur?\n"
            "2. BÃ¼yÃ¼me FIRSATLARINI tespit et â€” pazar, teknoloji, inovasyon\n"
            "3. Rekabet avantajÄ± potansiyelini deÄŸerlendir\n"
            "4. Sinerjileri bul â€” hangi alanlarda Ã§arpan etkisi oluÅŸur?\n"
            "5. HÄ±zlÄ± kazanÄ±mlarÄ± (quick wins) belirle â€” dÃ¼ÅŸÃ¼k eforla yÃ¼ksek getiri\n"
            "\nGerÃ§ekÃ§i iyimserlik â€” temelsiz umut deÄŸil, veriye dayalÄ± fÄ±rsat analizi."
        ),
        "focus_areas": ["fÄ±rsat", "bÃ¼yÃ¼me", "sinerji", "quick_win", "rekabet_avantajÄ±"],
        "risk_weight": 0.2,
        "opportunity_weight": 0.8,
    },
    PerspectiveType.DOMAIN_EXPERT: {
        "label": "SektÃ¶r UzmanÄ±",
        "description": "Tekstil/Ã¼retim sektÃ¶rÃ¼ne Ã¶zel teknik analiz",
        "system_prompt": (
            "Sen bir Tekstil ve Ãœretim SektÃ¶rÃ¼ UzmanÄ± ajanÄ±sÄ±n. GÃ¶revin:\n"
            "1. SektÃ¶re Ã–ZGÃœ faktÃ¶rleri analiz et â€” tedarik zinciri, hammadde, mevsimsellik\n"
            "2. SektÃ¶r BENCHMARK'larÄ± ile karÅŸÄ±laÅŸtÄ±r â€” rakipler ne yapÄ±yor?\n"
            "3. Teknolojik TRENDLERÄ° deÄŸerlendir â€” EndÃ¼stri 4.0, otomasyon, dijitalleÅŸme\n"
            "4. RegÃ¼lasyon ve uyumluluk gereksinimlerini kontrol et\n"
            "5. SektÃ¶r-spesifik KPI'larÄ± Ã¶ner ve hedef deÄŸerler belirle\n"
            "\nHer Ã¶neride sektÃ¶r referansÄ± ver â€” 'tekstil sektÃ¶rÃ¼nde bu oran genelde X-Y arasÄ±dÄ±r'."
        ),
        "focus_areas": ["sektÃ¶r_bilgisi", "benchmark", "trend", "regÃ¼lasyon", "kpi"],
        "risk_weight": 0.5,
        "opportunity_weight": 0.5,
    },
    PerspectiveType.ETHICIST: {
        "label": "Etik DeÄŸerlendirici",
        "description": "Etik, sÃ¼rdÃ¼rÃ¼lebilirlik, sosyal sorumluluk perspektifi",
        "system_prompt": (
            "Sen bir Ä°ÅŸ EtiÄŸi ve SÃ¼rdÃ¼rÃ¼lebilirlik UzmanÄ± ajanÄ±sÄ±n. GÃ¶revin:\n"
            "1. ETÄ°K boyutu analiz et â€” Ã§alÄ±ÅŸan haklarÄ±, adil ticaret, ÅŸeffaflÄ±k\n"
            "2. SÃœRDÃœRÃœLEBÄ°LÄ°RLÄ°K etkisini deÄŸerlendir â€” Ã§evresel ayak izi, karbon\n"
            "3. Sosyal SORUMLULUK perspektifini ekle â€” toplum etkisi, istihdam\n"
            "4. Uzun vadeli Ä°TÄ°BAR risklerini belirle\n"
            "5. ESG (Ã‡evresel, Sosyal, YÃ¶netiÅŸim) uyumluluÄŸunu kontrol et\n"
            "\nPratik Ã¶neriler sun â€” etik olan aynÄ± zamanda kÃ¢rlÄ± mÄ±?"
        ),
        "focus_areas": ["etik", "sÃ¼rdÃ¼rÃ¼lebilirlik", "esg", "itibar", "sosyal_sorumluluk"],
        "risk_weight": 0.4,
        "opportunity_weight": 0.4,
    },
    PerspectiveType.PRAGMATIST: {
        "label": "Pragmatist UygulayÄ±cÄ±",
        "description": "Uygulama fizibilitesi, kaynak/zaman/bÃ¼tÃ§e gerÃ§ekÃ§iliÄŸi",
        "system_prompt": (
            "Sen bir Pragmatist Uygulama UzmanÄ± ajanÄ±sÄ±n. GÃ¶revin:\n"
            "1. Uygulama FÄ°ZÄ°BÄ°LÄ°TESÄ°NÄ° deÄŸerlendir â€” gerÃ§ekten yapÄ±labilir mi?\n"
            "2. KAYNAK gereksinimlerini belirle â€” insan, para, zaman, teknoloji\n"
            "3. Uygulama ADIMLARI Ã¶ner â€” Ã¶nceliklendirme, milestone, timeline\n"
            "4. DARBOÄžAZLARI tespit et â€” nerede takÄ±labiliriz?\n"
            "5. HÄ±zlÄ± prototip / MVP yaklaÅŸÄ±mÄ± Ã¶ner â€” kÃ¼Ã§Ã¼k baÅŸla, hÄ±zlÄ± Ã¶ÄŸren\n"
            "\nHer Ã¶neride 'NASIL yapÄ±lÄ±r' sorusunu cevapla â€” strateji deÄŸil taktik."
        ),
        "focus_areas": ["fizibilite", "kaynak", "zaman", "darboÄŸaz", "uygulama_planÄ±"],
        "risk_weight": 0.4,
        "opportunity_weight": 0.5,
    },
}


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# PERSPEKTÄ°F SEÃ‡Ä°CÄ° â€” Soruya gÃ¶re hangi ajanlar aktif olacak
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def select_perspectives(
    question: str,
    department: str,
    mode: str,
    intent: str,
    explicit_perspectives: Optional[List[str]] = None,
) -> List[PerspectiveType]:
    """Soruya en uygun perspektif ajanlarÄ±nÄ± seÃ§.

    Args:
        question: KullanÄ±cÄ± sorusu
        department: Departman
        mode: Analiz modu
        intent: Router intent
        explicit_perspectives: Admin tarafÄ±ndan belirtilen perspektifler

    Returns:
        SeÃ§ilen perspektif listesi (3-6 arasÄ±)
    """
    # AÃ§Ä±kÃ§a belirtilmiÅŸse doÄŸrudan kullan
    if explicit_perspectives:
        selected = []
        for p in explicit_perspectives:
            try:
                selected.append(PerspectiveType(p))
            except ValueError:
                continue
        if len(selected) >= MIN_PERSPECTIVES:
            return selected[:MAX_PERSPECTIVES]

    q_lower = question.lower()
    scores: Dict[PerspectiveType, float] = {p: 0.0 for p in PerspectiveType}

    # â”€â”€â”€ Anahtar kelime eÅŸleÅŸtirmesi â”€â”€â”€
    risk_keywords = ["risk", "tehlike", "tehdit", "zarar", "kayÄ±p", "kriz", "sorun"]
    opportunity_keywords = ["fÄ±rsat", "bÃ¼yÃ¼me", "kazanÃ§", "potansiyel", "yatÄ±rÄ±m", "geniÅŸleme"]
    ethics_keywords = ["etik", "sÃ¼rdÃ¼rÃ¼lebilir", "Ã§evre", "sorumluluk", "esg", "karbon", "adil"]
    execution_keywords = ["uygula", "plan", "bÃ¼tÃ§e", "kaynak", "zaman", "sÃ¼reÃ§", "nasÄ±l"]
    comparison_keywords = ["karÅŸÄ±laÅŸtÄ±r", "alternatif", "seÃ§enek", "vs", "avantaj", "dezavantaj"]
    sector_keywords = ["sektÃ¶r", "pazar", "rekabet", "benchmark", "trend", "endÃ¼stri"]

    for kw in risk_keywords:
        if kw in q_lower:
            scores[PerspectiveType.RISK_ANALYST] += 2.0
            scores[PerspectiveType.DEVILS_ADVOCATE] += 1.0

    for kw in opportunity_keywords:
        if kw in q_lower:
            scores[PerspectiveType.OPTIMIST] += 2.0
            scores[PerspectiveType.PRAGMATIST] += 1.0

    for kw in ethics_keywords:
        if kw in q_lower:
            scores[PerspectiveType.ETHICIST] += 3.0

    for kw in execution_keywords:
        if kw in q_lower:
            scores[PerspectiveType.PRAGMATIST] += 2.0

    for kw in comparison_keywords:
        if kw in q_lower:
            scores[PerspectiveType.DEVILS_ADVOCATE] += 2.0
            scores[PerspectiveType.OPTIMIST] += 1.0

    for kw in sector_keywords:
        if kw in q_lower:
            scores[PerspectiveType.DOMAIN_EXPERT] += 2.0

    # â”€â”€â”€ Mod bazlÄ± boost â”€â”€â”€
    if mode in ("Ãœst DÃ¼zey Analiz", "CEO Raporu"):
        scores[PerspectiveType.DEVILS_ADVOCATE] += 2.0
        scores[PerspectiveType.RISK_ANALYST] += 1.5
        scores[PerspectiveType.OPTIMIST] += 1.0
        scores[PerspectiveType.PRAGMATIST] += 1.0
    elif mode == "Risk Analizi":
        scores[PerspectiveType.RISK_ANALYST] += 3.0
        scores[PerspectiveType.DEVILS_ADVOCATE] += 2.0
    elif mode in ("Strateji", "Tahmin"):
        scores[PerspectiveType.OPTIMIST] += 2.0
        scores[PerspectiveType.PRAGMATIST] += 1.5
        scores[PerspectiveType.DOMAIN_EXPERT] += 1.0

    # â”€â”€â”€ Departman bazlÄ± boost â”€â”€â”€
    if department in ("Ã¼retim", "kalite", "tedarik"):
        scores[PerspectiveType.DOMAIN_EXPERT] += 2.0
    if department in ("finans", "muhasebe"):
        scores[PerspectiveType.RISK_ANALYST] += 1.5
    if department in ("insan_kaynaklarÄ±", "ik"):
        scores[PerspectiveType.ETHICIST] += 1.5

    # â”€â”€â”€ Her zaman devÅŸil avukatÄ± dahil et (karÅŸÄ±t gÃ¶rÃ¼ÅŸ bel kemiÄŸi) â”€â”€â”€
    scores[PerspectiveType.DEVILS_ADVOCATE] += 1.0

    # Skor sÄ±rasÄ±na gÃ¶re en iyi perspektifleri seÃ§
    sorted_perspectives = sorted(scores.items(), key=lambda x: x[1], reverse=True)

    # Minimum skor eÅŸiÄŸi â€” en az 0.5 puan almÄ±ÅŸ olmalÄ±
    selected = [p for p, s in sorted_perspectives if s >= 0.5]

    # Minimum 3, maksimum 6
    if len(selected) < MIN_PERSPECTIVES:
        # Eksik kalanlarÄ± skor sÄ±rasÄ±yla doldur
        for p, _ in sorted_perspectives:
            if p not in selected:
                selected.append(p)
            if len(selected) >= MIN_PERSPECTIVES:
                break

    return selected[:MAX_PERSPECTIVES]


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# TETÄ°KLEME KARARI â€” Bu soru debate gerektirir mi?
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def should_trigger_debate(
    question: str,
    mode: str,
    intent: str,
    confidence: float = 100.0,
    force: bool = False,
) -> Tuple[bool, str]:
    """Bu soru multi-agent debate gerektirir mi?

    Returns:
        (trigger: bool, reason: str)
    """
    if force:
        return True, "manual_trigger"

    # KÄ±sa sorular debate'e girmez
    if len(question.strip()) < DEBATE_TRIGGER_MIN_LENGTH:
        return False, "too_short"

    # Sohbet/selamlama debate'e girmez
    if intent in ("sohbet", "selamlama"):
        return False, "casual_intent"

    # Mod bazlÄ± otomatik tetikleme
    if mode in DEBATE_TRIGGER_MODES:
        return True, f"mode_trigger:{mode}"

    # Anahtar kelime bazlÄ± tetikleme
    q_lower = question.lower()
    keyword_hits = sum(1 for kw in DEBATE_TRIGGER_KEYWORDS if kw in q_lower)
    if keyword_hits >= 2:
        return True, f"keyword_trigger:{keyword_hits}_hits"

    # DÃ¼ÅŸÃ¼k confidence ise debate ile gÃ¼Ã§lendir
    if confidence < 55:
        return True, f"low_confidence:{confidence}"

    return False, "no_trigger"


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# PERSPEKTÄ°F ANALÄ°Z OLUÅžTURUCU
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def generate_perspective_analysis(
    perspective: PerspectiveType,
    question: str,
    department: str,
    mode: str,
    existing_answer: str = "",
    rag_context: str = "",
    other_perspectives: Optional[List[PerspectiveAnalysis]] = None,
    round_number: int = 1,
) -> PerspectiveAnalysis:
    """Bir perspektif ajanÄ± iÃ§in analiz prompt'u oluÅŸtur ve analiz yap.

    Bu fonksiyon LLM Ã§aÄŸrÄ±sÄ± yapmaz â€” prompt ve yapÄ±yÄ± hazÄ±rlar.
    GerÃ§ek LLM Ã§aÄŸrÄ±sÄ± engine.py'den yapÄ±lÄ±r.

    Args:
        perspective: Perspektif tipi
        question: KullanÄ±cÄ± sorusu
        department: Departman
        mode: Analiz modu
        existing_answer: Varsa mevcut cevap (round 2+ iÃ§in)
        rag_context: RAG baÄŸlamÄ±
        other_perspectives: DiÄŸer perspektiflerin analizleri (round 2+ iÃ§in)
        round_number: TartÄ±ÅŸma turu numarasÄ±

    Returns:
        BoÅŸ PerspectiveAnalysis (LLM sonrasÄ± doldurulacak)
    """
    config = PERSPECTIVE_CONFIGS.get(perspective, {})
    t0 = time.time()

    analysis = PerspectiveAnalysis(
        perspective=perspective,
        label=config.get("label", perspective.value),
        summary="",
        arguments=[],
        recommendation="",
        risk_level=0.0,
        opportunity_level=0.0,
        confidence=0.5,
        generation_time_ms=0.0,
    )

    return analysis


def build_perspective_prompt(
    perspective: PerspectiveType,
    question: str,
    department: str,
    mode: str,
    existing_answer: str = "",
    rag_context: str = "",
    other_perspectives_text: str = "",
    round_number: int = 1,
) -> Tuple[str, str]:
    """Perspektif ajanÄ± iÃ§in system + user prompt oluÅŸtur.

    Returns:
        (system_prompt, user_prompt)
    """
    config = PERSPECTIVE_CONFIGS[perspective]

    system_prompt = config["system_prompt"]
    system_prompt += f"\n\nDepartman: {department}\nAnaliz Modu: {mode}"
    system_prompt += (
        "\n\nYanÄ±tÄ±nÄ± ÅŸu yapÄ±da ver:"
        "\n1. Ã–ZET (2-3 cÃ¼mle)"
        "\n2. ANA ARGÃœMANLAR (en az 2, en fazla 4)"
        "\n   - Her argÃ¼man iÃ§in: ArgÃ¼man + KanÄ±t/GerekÃ§e + GÃ¼Ã§ (gÃ¼Ã§lÃ¼/orta/zayÄ±f)"
        "\n3. RÄ°SK SEVÄ°YESÄ° (0-10)"
        "\n4. FIRSAT SEVÄ°YESÄ° (0-10)"
        "\n5. Ã–NERÄ° (1 paragraf)"
    )

    user_prompt = f"Soru: {question}"

    if existing_answer:
        user_prompt += f"\n\nMevcut Analiz:\n{existing_answer[:1500]}"

    if rag_context:
        user_prompt += f"\n\nBilgi TabanÄ±:\n{rag_context[:1000]}"

    if other_perspectives_text and round_number > 1:
        user_prompt += (
            f"\n\n--- DÄ°ÄžER PERSPEKTÄ°FLER (Tur {round_number - 1}) ---\n"
            f"{other_perspectives_text[:2000]}\n"
            "YukarÄ±daki perspektifleri dikkate alarak kendi gÃ¶rÃ¼ÅŸÃ¼nÃ¼ gÃ¼ncelle. "
            "DesteklediÄŸin noktalarÄ± belirt, karÅŸÄ± olduklarÄ±nÄ± gerekÃ§esiyle Ã§Ã¼rÃ¼t."
        )

    return system_prompt, user_prompt


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ARGÃœMAN PARSER â€” LLM Ã§Ä±ktÄ±sÄ±ndan yapÄ±sal argÃ¼man Ã§Ä±karma
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def parse_perspective_response(
    raw_text: str,
    perspective: PerspectiveType,
    round_number: int = 1,
) -> PerspectiveAnalysis:
    """LLM yanÄ±tÄ±nÄ± yapÄ±sal PerspectiveAnalysis'e dÃ¶nÃ¼ÅŸtÃ¼r.

    Heuristic parser â€” LLM'in yapÄ±sal Ã§Ä±ktÄ± vermesi garanti deÄŸil,
    bu yÃ¼zden regex + keyword tabanlÄ± esnek parsing yapar.
    """
    import re

    config = PERSPECTIVE_CONFIGS[perspective]
    lines = raw_text.strip().split("\n")
    text_lower = raw_text.lower()

    # â”€â”€ Ã–zet Ã§Ä±karma â”€â”€
    summary = ""
    for i, line in enumerate(lines):
        if any(kw in line.lower() for kw in ["Ã¶zet", "summary", "genel deÄŸerlendirme"]):
            # Sonraki 2-3 satÄ±rÄ± Ã¶zet olarak al
            summary_lines = []
            for j in range(i + 1, min(i + 4, len(lines))):
                clean = lines[j].strip().lstrip("-â€¢*")
                if clean and not any(kw in clean.lower() for kw in ["argÃ¼man", "risk", "Ã¶neri", "fÄ±rsat"]):
                    summary_lines.append(clean)
                else:
                    break
            summary = " ".join(summary_lines)
            break
    if not summary and lines:
        # Ä°lk anlamlÄ± satÄ±rÄ± Ã¶zet olarak kullan
        for line in lines[:5]:
            clean = line.strip().lstrip("-â€¢*#123456789. ")
            if len(clean) > 20:
                summary = clean[:300]
                break

    # â”€â”€ ArgÃ¼man Ã§Ä±karma â”€â”€
    arguments = []
    arg_pattern = re.compile(
        r"(?:argÃ¼man|argument|nokta|madde|claim|iddia|gÃ¶rÃ¼ÅŸ)\s*[:\-]?\s*(.+)",
        re.IGNORECASE
    )

    current_claim = ""
    for line in lines:
        clean = line.strip()
        # NumaralÄ± madde veya bullet point
        if re.match(r"^[\d]+[.)]\s+", clean) or clean.startswith(("- ", "â€¢ ", "* ")):
            claim_text = re.sub(r"^[\d]+[.)]\s+|^[-â€¢*]\s+", "", clean).strip()
            # Ã‡ok kÄ±sa veya baÅŸlÄ±k ise atla
            if len(claim_text) > 15 and not any(
                kw in claim_text.lower() for kw in
                ["Ã¶zet", "risk seviyesi", "fÄ±rsat seviyesi", "Ã¶neri"]
            ):
                if current_claim:
                    arguments.append(Argument(
                        perspective=perspective,
                        claim=current_claim,
                        strength=ArgumentStrength.MODERATE,
                        confidence=0.6,
                        round_number=round_number,
                    ))
                current_claim = claim_text
            else:
                current_claim = ""
        elif current_claim and clean:
            # Devam satÄ±rÄ± â€” evidence olarak ekle
            if arguments and arguments[-1].claim == current_claim:
                arguments[-1].evidence.append(clean[:200])

    # Son argÃ¼manÄ± ekle
    if current_claim:
        arguments.append(Argument(
            perspective=perspective,
            claim=current_claim,
            strength=ArgumentStrength.MODERATE,
            confidence=0.6,
            round_number=round_number,
        ))

    # â”€â”€ ArgÃ¼man gÃ¼cÃ¼ belirleme â”€â”€
    strong_markers = ["kesinlikle", "mutlaka", "kritik", "hayati", "zorunlu", "kanÄ±tlanmÄ±ÅŸ"]
    weak_markers = ["belki", "olabilir", "dÃ¼ÅŸÃ¼nÃ¼lebilir", "ihtimal", "spekÃ¼lasyon"]
    for arg in arguments:
        claim_lower = arg.claim.lower()
        if any(m in claim_lower for m in strong_markers):
            arg.strength = ArgumentStrength.STRONG
            arg.confidence = 0.8
        elif any(m in claim_lower for m in weak_markers):
            arg.strength = ArgumentStrength.WEAK
            arg.confidence = 0.4

    # â”€â”€ Risk/FÄ±rsat seviyesi â”€â”€
    risk_level = 0.5
    opportunity_level = 0.5
    risk_match = re.search(r"risk\s*(?:seviye|skor|puan)\s*[:\-]?\s*(\d+)", text_lower)
    if risk_match:
        risk_level = min(int(risk_match.group(1)), 10) / 10.0
    opp_match = re.search(r"fÄ±rsat\s*(?:seviye|skor|puan)\s*[:\-]?\s*(\d+)", text_lower)
    if opp_match:
        opportunity_level = min(int(opp_match.group(1)), 10) / 10.0

    # Perspektif tipine gÃ¶re varsayÄ±lan risk/fÄ±rsat aÄŸÄ±rlÄ±ÄŸÄ±
    if not risk_match:
        risk_level = config.get("risk_weight", 0.5)
    if not opp_match:
        opportunity_level = config.get("opportunity_weight", 0.5)

    # â”€â”€ Ã–neri Ã§Ä±karma â”€â”€
    recommendation = ""
    for i, line in enumerate(lines):
        if any(kw in line.lower() for kw in ["Ã¶neri", "tavsiye", "recommendation", "sonuÃ§"]):
            rec_lines = []
            for j in range(i + 1, min(i + 5, len(lines))):
                clean = lines[j].strip().lstrip("-â€¢*")
                if clean:
                    rec_lines.append(clean)
                else:
                    break
            recommendation = " ".join(rec_lines)
            break
    if not recommendation and lines:
        recommendation = lines[-1].strip()[:300]

    # â”€â”€ Confidence hesapla â”€â”€
    arg_count = len(arguments)
    evidence_count = sum(len(a.evidence) for a in arguments)
    strong_count = sum(1 for a in arguments if a.strength == ArgumentStrength.STRONG)

    confidence = 0.5
    if arg_count > 0:
        confidence = min(0.9, 0.4 + (arg_count * 0.1) + (evidence_count * 0.05) + (strong_count * 0.1))

    return PerspectiveAnalysis(
        perspective=perspective,
        label=config.get("label", perspective.value),
        summary=summary,
        arguments=arguments[:6],  # Max 6 argÃ¼man
        recommendation=recommendation,
        risk_level=risk_level,
        opportunity_level=opportunity_level,
        confidence=round(confidence, 2),
    )


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# KONSENSÃœS TESPÄ°TÄ°
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

class ConsensusDetector:
    """Perspektifler arasÄ± uzlaÅŸma/ayrÄ±ÅŸma analizi."""

    @staticmethod
    def analyze(analyses: List[PerspectiveAnalysis]) -> ConsensusResult:
        """TÃ¼m perspektif analizlerini karÅŸÄ±laÅŸtÄ±rarak uzlaÅŸma tespiti yap.

        MantÄ±k:
        1. Risk seviyesi yakÄ±nlÄ±ÄŸÄ± â†’ agreement
        2. Ã–neri yÃ¶nÃ¼ benzerliÄŸi â†’ agreement
        3. ArgÃ¼man Ã§atÄ±ÅŸmasÄ± â†’ disagreement
        4. Ortalama uyum skoru â†’ consensus_score
        """
        if not analyses:
            return ConsensusResult(
                outcome=DebateOutcome.DEADLOCK,
                consensus_score=0.0,
            )

        n = len(analyses)
        if n == 1:
            return ConsensusResult(
                outcome=DebateOutcome.CONSENSUS,
                consensus_score=1.0,
                agreed_points=[analyses[0].summary],
            )

        # â”€â”€ Risk seviyesi uyumu â”€â”€
        risk_levels = [a.risk_level for a in analyses]
        avg_risk = sum(risk_levels) / n
        risk_variance = sum((r - avg_risk) ** 2 for r in risk_levels) / n
        risk_agreement = max(0.0, 1.0 - (risk_variance * 4))  # 0-1

        # â”€â”€ FÄ±rsat seviyesi uyumu â”€â”€
        opp_levels = [a.opportunity_level for a in analyses]
        avg_opp = sum(opp_levels) / n
        opp_variance = sum((o - avg_opp) ** 2 for o in opp_levels) / n
        opp_agreement = max(0.0, 1.0 - (opp_variance * 4))

        # â”€â”€ Confidence uyumu â”€â”€
        confidences = [a.confidence for a in analyses]
        avg_conf = sum(confidences) / n
        conf_variance = sum((c - avg_conf) ** 2 for c in confidences) / n
        conf_agreement = max(0.0, 1.0 - (conf_variance * 4))

        # â”€â”€ ArgÃ¼man yÃ¶nÃ¼ analizi â”€â”€
        positive_count = 0
        negative_count = 0
        neutral_count = 0

        positive_markers = [
            "fÄ±rsat", "avantaj", "bÃ¼yÃ¼me", "kazanÃ§", "olumlu", "pozitif",
            "destekle", "yap", "uygula", "baÅŸla", "ilerle",
        ]
        negative_markers = [
            "risk", "tehlike", "zarar", "kayÄ±p", "olumsuz", "negatif",
            "dikkat", "dur", "bekle", "kaÃ§Ä±n", "riskli",
        ]

        for analysis in analyses:
            rec_lower = analysis.recommendation.lower()
            pos_hits = sum(1 for m in positive_markers if m in rec_lower)
            neg_hits = sum(1 for m in negative_markers if m in rec_lower)

            if pos_hits > neg_hits:
                positive_count += 1
            elif neg_hits > pos_hits:
                negative_count += 1
            else:
                neutral_count += 1

        # YÃ¶n uyumu
        max_direction = max(positive_count, negative_count, neutral_count)
        direction_agreement = max_direction / n

        # â”€â”€ Toplam uzlaÅŸma skoru â”€â”€
        consensus_score = (
            risk_agreement * 0.25 +
            opp_agreement * 0.20 +
            conf_agreement * 0.15 +
            direction_agreement * 0.40
        )

        # â”€â”€ UzlaÅŸÄ±lan ve ayrÄ±ÅŸan noktalar â”€â”€
        agreed_points = []
        disputed_points = []
        minority_views = []
        risk_warnings = []

        # TÃ¼m Ã¶nerileri topla ve benzerlik kontrol et
        all_recommendations = [(a.perspective.value, a.recommendation) for a in analyses]

        # YÃ¼ksek riskleri uyarÄ± olarak ekle
        for a in analyses:
            if a.risk_level >= 0.7:
                risk_warnings.append(
                    f"[{a.label}] YÃ¼ksek risk uyarÄ±sÄ± (seviye: {a.risk_level:.1f}): "
                    f"{a.summary[:100]}"
                )

        # AzÄ±nlÄ±k gÃ¶rÃ¼ÅŸlerini belirle
        if positive_count > 0 and negative_count > 0:
            minority_direction = "pozitif" if positive_count < negative_count else "negatif"
            for a in analyses:
                rec_lower = a.recommendation.lower()
                pos_hits = sum(1 for m in positive_markers if m in rec_lower)
                neg_hits = sum(1 for m in negative_markers if m in rec_lower)

                is_positive = pos_hits > neg_hits
                if (minority_direction == "pozitif" and is_positive) or \
                   (minority_direction == "negatif" and not is_positive):
                    minority_views.append(f"[{a.label}] {a.recommendation[:150]}")

        # UzlaÅŸÄ±lan noktalar â€” birden fazla perspektifin paylaÅŸtÄ±ÄŸÄ± Ã¶neriler
        for a in analyses:
            if a.confidence >= 0.6:
                agreed_points.append(f"[{a.label}] {a.summary[:150]}")

        # â”€â”€ SonuÃ§ belirleme â”€â”€
        if consensus_score >= STRONG_CONSENSUS_THRESHOLD:
            outcome = DebateOutcome.STRONG_CONSENSUS
            confidence_adj = CONFIDENCE_BOOST_ON_CONSENSUS
        elif consensus_score >= CONSENSUS_THRESHOLD:
            outcome = DebateOutcome.CONSENSUS
            confidence_adj = CONFIDENCE_BOOST_ON_CONSENSUS * 0.6
        elif consensus_score >= 0.50:
            outcome = DebateOutcome.MAJORITY
            confidence_adj = 0.0
        elif consensus_score >= 0.30:
            outcome = DebateOutcome.SPLIT
            confidence_adj = -CONFIDENCE_PENALTY_ON_SPLIT
        else:
            outcome = DebateOutcome.DEADLOCK
            confidence_adj = -CONFIDENCE_PENALTY_ON_SPLIT * 1.5

        return ConsensusResult(
            outcome=outcome,
            consensus_score=round(consensus_score, 3),
            agreed_points=agreed_points,
            disputed_points=disputed_points,
            minority_views=minority_views,
            risk_warnings=risk_warnings,
            confidence_adjustment=confidence_adj,
        )


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# SENTEZ MOTORU â€” TÃ¼m perspektifleri birleÅŸtiren final Ã§Ä±ktÄ±
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def build_synthesis_prompt(
    question: str,
    analyses: List[PerspectiveAnalysis],
    consensus: ConsensusResult,
    department: str,
    mode: str,
) -> Tuple[str, str]:
    """Sentez ajanÄ± iÃ§in prompt oluÅŸtur.

    Returns:
        (system_prompt, user_prompt)
    """
    system_prompt = (
        "Sen bir Stratejik Sentez UzmanÄ±sÄ±n. Birden fazla uzman perspektifini "
        "birleÅŸtirerek dengeli, kapsamlÄ± ve uygulanabilir bir final analiz Ã¼retirsin.\n\n"
        "GÃ¶revin:\n"
        "1. TÃ¼m perspektiflerin gÃ¼Ã§lÃ¼ yÃ¶nlerini BÄ°RLEÅžTÄ°R\n"
        "2. Ã‡eliÅŸen gÃ¶rÃ¼ÅŸleri DENGE ile sun â€” 'A grubu ÅŸunu sÃ¶ylÃ¼yor, B grubu bunu'\n"
        "3. Risk uyarÄ±larÄ±nÄ± VURGULA ama fÄ±rsatlarÄ± da gÃ¶ster\n"
        "4. NET bir nihai Ã–NERÄ° ver â€” evet/hayÄ±r/koÅŸullu\n"
        "5. Aksiyon maddelerini LÄ°STELE â€” kÄ±sa/orta/uzun vade\n\n"
        f"Departman: {department}\nMod: {mode}\n"
        f"UzlaÅŸma Durumu: {consensus.outcome.value} (skor: {consensus.consensus_score:.2f})"
    )

    user_prompt = f"## Analiz Edilen Soru\n{question}\n\n"
    user_prompt += "## Uzman Perspektifleri\n\n"

    for analysis in analyses:
        user_prompt += f"### {analysis.label}\n"
        user_prompt += f"Ã–zet: {analysis.summary}\n"
        user_prompt += f"Risk: {analysis.risk_level:.1f}/1.0 | FÄ±rsat: {analysis.opportunity_level:.1f}/1.0\n"
        if analysis.arguments:
            user_prompt += "ArgÃ¼manlar:\n"
            for arg in analysis.arguments[:3]:
                user_prompt += f"  - [{arg.strength.value}] {arg.claim}\n"
        user_prompt += f"Ã–neri: {analysis.recommendation}\n\n"

    if consensus.risk_warnings:
        user_prompt += "\n## Risk UyarÄ±larÄ±\n"
        for w in consensus.risk_warnings:
            user_prompt += f"âš  {w}\n"

    if consensus.minority_views:
        user_prompt += "\n## AzÄ±nlÄ±k GÃ¶rÃ¼ÅŸleri (dikkate al)\n"
        for mv in consensus.minority_views:
            user_prompt += f"ðŸ“Œ {mv}\n"

    user_prompt += (
        "\n\nYukarÄ±daki tÃ¼m perspektifleri sentezleyerek kapsamlÄ± bir final analiz yaz. "
        "UzlaÅŸÄ±lan noktalarÄ±, tartÄ±ÅŸmalÄ± alanlarÄ± ve net Ã¶nerileri ayrÄ± ayrÄ± belirt."
    )

    return system_prompt, user_prompt


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# DEBATE TRACKER â€” GeÃ§miÅŸ tartÄ±ÅŸma ve performans takibi
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

class DebateTracker:
    """TartÄ±ÅŸma geÃ§miÅŸi ve performans analizi."""

    def __init__(self):
        self._debates: List[DebateResult] = []
        self._perspective_stats: Dict[str, Dict[str, Any]] = defaultdict(
            lambda: {"used": 0, "avg_confidence": 0.0, "total_arguments": 0}
        )
        self._consensus_stats: Dict[str, int] = defaultdict(int)
        self._department_stats: Dict[str, Dict[str, Any]] = defaultdict(
            lambda: {"debates": 0, "avg_consensus_score": 0.0}
        )

    def record(self, result: DebateResult):
        """TartÄ±ÅŸma sonucunu kaydet."""
        self._debates.append(result)
        if len(self._debates) > MAX_DEBATE_HISTORY:
            self._debates = self._debates[-MAX_DEBATE_HISTORY:]

        # Perspektif istatistikleri
        for analysis in result.analyses:
            key = analysis.perspective.value
            stats = self._perspective_stats[key]
            stats["used"] += 1
            n = stats["used"]
            stats["avg_confidence"] = round(
                ((stats["avg_confidence"] * (n - 1)) + analysis.confidence) / n, 3
            )
            stats["total_arguments"] += len(analysis.arguments)

        # KonsensÃ¼s istatistikleri
        if result.consensus:
            self._consensus_stats[result.consensus.outcome.value] += 1

        # Departman istatistikleri
        dept_key = result.department
        ds = self._department_stats[dept_key]
        ds["debates"] += 1
        n = ds["debates"]
        cs = result.consensus.consensus_score if result.consensus else 0.5
        ds["avg_consensus_score"] = round(
            ((ds["avg_consensus_score"] * (n - 1)) + cs) / n, 3
        )

        logger.info("debate_recorded",
                     debate_id=result.debate_id,
                     perspectives=len(result.perspectives_used),
                     outcome=result.consensus.outcome.value if result.consensus else "none",
                     confidence_delta=round(result.confidence_after - result.confidence_before, 1))

    def get_recent(self, n: int = 20) -> List[dict]:
        """Son N tartÄ±ÅŸma."""
        return [d.to_dict() for d in self._debates[-n:]]

    def get_statistics(self) -> dict:
        """Genel tartÄ±ÅŸma istatistikleri."""
        total = len(self._debates)
        if total == 0:
            return {"total_debates": 0}

        avg_confidence_delta = sum(
            d.confidence_after - d.confidence_before for d in self._debates
        ) / total

        avg_perspectives = sum(len(d.perspectives_used) for d in self._debates) / total

        avg_time = sum(d.total_time_ms for d in self._debates) / total

        return {
            "total_debates": total,
            "avg_confidence_delta": round(avg_confidence_delta, 2),
            "avg_perspectives_used": round(avg_perspectives, 1),
            "avg_debate_time_ms": round(avg_time, 1),
            "consensus_distribution": dict(self._consensus_stats),
            "perspective_stats": dict(self._perspective_stats),
            "department_stats": dict(self._department_stats),
        }

    def get_dashboard(self) -> dict:
        """Tam dashboard verisi."""
        return {
            "available": True,
            "statistics": self.get_statistics(),
            "recent_debates": self.get_recent(10),
            "perspective_configs": {
                p.value: {
                    "label": c["label"],
                    "description": c["description"],
                    "focus_areas": c["focus_areas"],
                }
                for p, c in PERSPECTIVE_CONFIGS.items()
            },
            "settings": {
                "max_rounds": MAX_DEBATE_ROUNDS,
                "min_perspectives": MIN_PERSPECTIVES,
                "max_perspectives": MAX_PERSPECTIVES,
                "consensus_threshold": CONSENSUS_THRESHOLD,
                "strong_consensus_threshold": STRONG_CONSENSUS_THRESHOLD,
                "confidence_boost": CONFIDENCE_BOOST_ON_CONSENSUS,
                "confidence_penalty": CONFIDENCE_PENALTY_ON_SPLIT,
            },
        }

    def reset(self):
        """TÃ¼m tartÄ±ÅŸma verisini sÄ±fÄ±rla."""
        self._debates.clear()
        self._perspective_stats.clear()
        self._consensus_stats.clear()
        self._department_stats.clear()
        logger.info("debate_tracker_reset")


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ANA ORKESTRATÃ–R â€” MultiAgentDebateEngine
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

class MultiAgentDebateEngine:
    """Multi-Agent Debate orkestratÃ¶rÃ¼.

    KullanÄ±m (engine.py'den):
        engine = debate_engine  # singleton
        trigger, reason = engine.should_debate(question, mode, intent, confidence)
        if trigger:
            debate_result = await engine.run_debate(question, department, mode, ...)
            final_answer = debate_result.synthesis
            adjusted_confidence = debate_result.confidence_after
    """

    def __init__(self):
        self.tracker = DebateTracker()
        self._enabled: bool = True
        self._started_at: str = _utcnow_str()

    def should_debate(
        self,
        question: str,
        mode: str,
        intent: str,
        confidence: float = 100.0,
        force: bool = False,
    ) -> Tuple[bool, str]:
        """Debate tetikleme kararÄ±."""
        if not self._enabled and not force:
            return False, "debate_disabled"
        return should_trigger_debate(question, mode, intent, confidence, force)

    def select_perspectives(
        self,
        question: str,
        department: str,
        mode: str,
        intent: str,
        explicit: Optional[List[str]] = None,
    ) -> List[PerspectiveType]:
        """Perspektif seÃ§imi."""
        return select_perspectives(question, department, mode, intent, explicit)

    def build_perspective_prompts(
        self,
        perspectives: List[PerspectiveType],
        question: str,
        department: str,
        mode: str,
        existing_answer: str = "",
        rag_context: str = "",
        round_number: int = 1,
        previous_analyses: Optional[List[PerspectiveAnalysis]] = None,
    ) -> List[Dict[str, Any]]:
        """Her perspektif iÃ§in prompt hazÄ±rla.

        Returns:
            [{perspective, label, system_prompt, user_prompt}, ...]
        """
        other_text = ""
        if previous_analyses and round_number > 1:
            parts = []
            for a in previous_analyses:
                parts.append(f"### {a.label}\n{a.summary}\nÃ–neri: {a.recommendation}")
            other_text = "\n\n".join(parts)

        prompts = []
        for p in perspectives:
            sys_prompt, usr_prompt = build_perspective_prompt(
                perspective=p,
                question=question,
                department=department,
                mode=mode,
                existing_answer=existing_answer,
                rag_context=rag_context,
                other_perspectives_text=other_text,
                round_number=round_number,
            )
            prompts.append({
                "perspective": p,
                "label": PERSPECTIVE_CONFIGS[p]["label"],
                "system_prompt": sys_prompt,
                "user_prompt": usr_prompt,
            })

        return prompts

    def process_responses(
        self,
        perspectives: List[PerspectiveType],
        raw_responses: List[str],
        round_number: int = 1,
    ) -> List[PerspectiveAnalysis]:
        """LLM yanÄ±tlarÄ±nÄ± parse edip yapÄ±sal analizlere dÃ¶nÃ¼ÅŸtÃ¼r."""
        analyses = []
        for perspective, raw_text in zip(perspectives, raw_responses):
            try:
                analysis = parse_perspective_response(raw_text, perspective, round_number)
                analyses.append(analysis)
            except Exception as e:
                logger.warning("perspective_parse_error",
                               perspective=perspective.value, error=str(e))
                # Fallback â€” ham metni Ã¶zet olarak kullan
                analyses.append(PerspectiveAnalysis(
                    perspective=perspective,
                    label=PERSPECTIVE_CONFIGS[perspective]["label"],
                    summary=raw_text[:300],
                    confidence=0.4,
                ))
        return analyses

    def detect_consensus(self, analyses: List[PerspectiveAnalysis]) -> ConsensusResult:
        """UzlaÅŸma tespiti."""
        return ConsensusDetector.analyze(analyses)

    def build_synthesis(
        self,
        question: str,
        analyses: List[PerspectiveAnalysis],
        consensus: ConsensusResult,
        department: str,
        mode: str,
    ) -> Tuple[str, str]:
        """Sentez prompt'u oluÅŸtur."""
        return build_synthesis_prompt(question, analyses, consensus, department, mode)

    def finalize_debate(
        self,
        question: str,
        department: str,
        mode: str,
        perspectives: List[PerspectiveType],
        analyses: List[PerspectiveAnalysis],
        rounds: List[DebateRound],
        consensus: ConsensusResult,
        synthesis_text: str,
        confidence_before: float,
        total_time_ms: float,
        triggered_by: str = "auto",
    ) -> DebateResult:
        """TartÄ±ÅŸmayÄ± sonlandÄ±r, kaydet ve DebateResult dÃ¶ndÃ¼r."""
        debate_id = f"DBT-{uuid.uuid4().hex[:8]}"

        confidence_after = min(100, max(0,
            confidence_before + consensus.confidence_adjustment
        ))

        # Sentezden final Ã¶neri Ã§Ä±kar
        final_recommendation = synthesis_text[:500] if synthesis_text else ""

        result = DebateResult(
            debate_id=debate_id,
            question=question,
            department=department,
            mode=mode,
            timestamp=_utcnow_str(),
            perspectives_used=perspectives,
            analyses=analyses,
            rounds=rounds,
            consensus=consensus,
            synthesis=synthesis_text,
            final_recommendation=final_recommendation,
            confidence_before=confidence_before,
            confidence_after=confidence_after,
            total_time_ms=total_time_ms,
            triggered_by=triggered_by,
        )

        self.tracker.record(result)
        return result

    def get_dashboard(self) -> dict:
        """Dashboard verisi."""
        return self.tracker.get_dashboard()

    def set_enabled(self, enabled: bool) -> dict:
        """Debate sistemini aÃ§/kapat."""
        old = self._enabled
        self._enabled = enabled
        logger.info("debate_engine_toggled", old=old, new=enabled)
        return {"enabled": enabled, "previous": old}

    def reset(self):
        """TÃ¼m tartÄ±ÅŸma verisini sÄ±fÄ±rla."""
        self.tracker.reset()
        self._started_at = _utcnow_str()
        logger.info("debate_engine_reset")


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# GLOBAL SINGLETON
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

debate_engine: MultiAgentDebateEngine = MultiAgentDebateEngine()


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# KOLAYLIK FONKSÄ°YONLARI â€” engine.py entegrasyonu
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def check_debate_trigger(
    question: str, mode: str, intent: str, confidence: float = 100.0, force: bool = False,
) -> Tuple[bool, str]:
    """Debate tetikleme kontrolÃ¼."""
    return debate_engine.should_debate(question, mode, intent, confidence, force)


def get_debate_dashboard() -> dict:
    """Dashboard verisi."""
    return debate_engine.get_dashboard()
