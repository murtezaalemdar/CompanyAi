"""Reflection Layer â€” LLM YanÄ±t Kalite Kontrol ve Self-Evaluation

Enterprise Tier-0 seviye reflection:
- 5 kriterli kalite deÄŸerlendirmesi
- Dinamik confidence score (0-100)
- DÃ¼ÅŸÃ¼k gÃ¼venli yanÄ±tlarda otomatik retry
- Hallucination detection (sayÄ±sal tutarsÄ±zlÄ±k)
"""

import re
import json
import structlog
from typing import Optional

logger = structlog.get_logger()

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# 1. DEÄERLENDÄ°RME KRÄ°TERLERÄ°
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

EVALUATION_CRITERIA = {
    "data_accuracy": {
        "name": "Veri DoÄŸruluÄŸu",
        "weight": 0.25,
        "checks": [
            "SayÄ±sal deÄŸerler tutarlÄ± mÄ±?",
            "Birimler doÄŸru mu (â‚º, %, kg)?",
            "Toplam/ortalama hesaplarÄ± doÄŸru mu?",
        ],
    },
    "logical_consistency": {
        "name": "MantÄ±ksal TutarlÄ±lÄ±k",
        "weight": 0.20,
        "checks": [
            "SonuÃ§lar Ã¶ncÃ¼lleri ile tutarlÄ± mÄ±?",
            "Ã‡eliÅŸkili ifadeler var mÄ±?",
            "Neden-sonuÃ§ iliÅŸkisi doÄŸru mu?",
        ],
    },
    "financial_reasoning": {
        "name": "Finansal AkÄ±l YÃ¼rÃ¼tme",
        "weight": 0.20,
        "checks": [
            "Finansal etkiler somut hesaplanmÄ±ÅŸ mÄ±?",
            "Maliyet/gelir projeksiyonlarÄ± mantÄ±klÄ± mÄ±?",
            "Risk-getiri dengesi deÄŸerlendirilmiÅŸ mi?",
        ],
    },
    "risk_clarity": {
        "name": "Risk NetliÄŸi",
        "weight": 0.15,
        "checks": [
            "Riskler belirlenmiÅŸ mi?",
            "Risk seviyesi (DÃ¼ÅŸÃ¼k/Orta/YÃ¼ksek/Kritik) ifade edilmiÅŸ mi?",
            "Risk azaltma Ã¶nerileri var mÄ±?",
        ],
    },
    "strategic_depth": {
        "name": "Stratejik Derinlik",
        "weight": 0.20,
        "checks": [
            "KÄ±sa/orta/uzun vadeli perspektif var mÄ±?",
            "Somut aksiyon Ã¶nerileri var mÄ±?",
            "Alternatif senaryolar dÃ¼ÅŸÃ¼nÃ¼lmÃ¼ÅŸ mÃ¼?",
        ],
    },
}

# Otomatik yeniden analiz eÅŸiÄŸi
AUTO_REANALYZE_THRESHOLD = 60
MAX_RETRY_COUNT = 2  # En fazla 2 kez retry (toplam 3 deneme â€” self-correction loop)


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# 2. HIZLI DEÄERLENDÄ°RME â€” LLM KULLANMADAN
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def quick_evaluate(answer: str, question: str, mode: str = "Sohbet") -> dict:
    """LLM kullanmadan hÄ±zlÄ± kalite deÄŸerlendirmesi yap.
    
    Args:
        answer: LLM'in Ã¼rettiÄŸi yanÄ±t
        question: KullanÄ±cÄ±nÄ±n sorusu
        mode: YanÄ±t modu (Sohbet, Analiz, Rapor vb.)
    
    Returns:
        {
            "confidence": 0-100,
            "criteria_scores": {...},
            "issues": [...],
            "pass": True/False,
            "suggestions": [...]
        }
    """
    scores = {}
    issues = []
    suggestions = []
    
    # â”€â”€ Veri DoÄŸruluÄŸu â”€â”€
    data_score = _check_data_accuracy(answer, question)
    scores["data_accuracy"] = data_score
    if data_score < 50:
        issues.append("SayÄ±sal veri yetersiz veya tutarsÄ±z")
        suggestions.append("YanÄ±tta somut sayÄ±sal veriler kullan")
    
    # â”€â”€ MantÄ±ksal TutarlÄ±lÄ±k â”€â”€
    logic_score = _check_logical_consistency(answer)
    scores["logical_consistency"] = logic_score
    if logic_score < 50:
        issues.append("YanÄ±tta Ã§eliÅŸkili ifadeler olabilir")
        suggestions.append("Neden-sonuÃ§ iliÅŸkisini gÃ¼Ã§lendir")
    
    # â”€â”€ Finansal AkÄ±l YÃ¼rÃ¼tme â”€â”€
    financial_score = _check_financial_reasoning(answer, mode)
    scores["financial_reasoning"] = financial_score
    if financial_score < 50 and mode in ("Analiz", "Rapor", "Ã–neri"):
        issues.append("Finansal etki hesabÄ± eksik")
        suggestions.append("â‚º cinsinden maliyet/gelir etkisi ekle")
    
    # â”€â”€ Risk NetliÄŸi â”€â”€
    risk_score = _check_risk_clarity(answer, mode)
    scores["risk_clarity"] = risk_score
    if risk_score < 50 and mode in ("Analiz", "Rapor", "Acil"):
        issues.append("Risk deÄŸerlendirmesi yetersiz")
        suggestions.append("Risk seviye ve azaltma Ã¶neri ekle")
    
    # â”€â”€ Stratejik Derinlik â”€â”€
    strategic_score = _check_strategic_depth(answer, mode)
    scores["strategic_depth"] = strategic_score
    if strategic_score < 50 and mode in ("Analiz", "Rapor", "Ã–neri"):
        issues.append("Stratejik derinlik eksik")
        suggestions.append("KÄ±sa/orta/uzun vade Ã¶nerileri ekle")
    
    # â”€â”€ Hallucination Check â”€â”€
    hallucination_issues = _check_hallucination(answer, question)
    if hallucination_issues:
        issues.extend(hallucination_issues)
        for key in scores:
            scores[key] = max(20, scores[key] - 20)
    
    # â”€â”€ Final Confidence Hesaplama â”€â”€
    weighted_score = sum(
        scores[key] * EVALUATION_CRITERIA[key]["weight"]
        for key in scores
    )
    
    # Mod bazlÄ± ayarlama â€” Sohbet modunda criteria daha yumuÅŸak
    if mode == "Sohbet":
        weighted_score = min(95, weighted_score + 25)
    elif mode == "Bilgi":
        weighted_score = min(95, weighted_score + 15)
    
    # YanÄ±t uzunluÄŸu bonusu/cezasÄ±
    word_count = len(answer.split())
    if mode in ("Analiz", "Rapor") and word_count < 50:
        weighted_score = max(30, weighted_score - 15)
        issues.append("YanÄ±t Ã§ok kÄ±sa, analiz derinliÄŸi yetersiz")
    elif word_count > 30:
        weighted_score = min(100, weighted_score + 5)
    
    confidence = round(weighted_score, 1)
    passed = confidence >= AUTO_REANALYZE_THRESHOLD
    
    return {
        "confidence": confidence,
        "criteria_scores": {
            EVALUATION_CRITERIA[k]["name"]: round(v, 1)
            for k, v in scores.items()
        },
        "issues": issues,
        "pass": passed,
        "suggestions": suggestions,
        "should_retry": not passed and mode in ("Analiz", "Rapor", "Ã–neri", "Acil"),
    }


def _check_data_accuracy(answer: str, question: str) -> float:
    """SayÄ±sal veri doÄŸruluÄŸu kontrolÃ¼."""
    score = 60.0  # BaÅŸlangÄ±Ã§
    
    # SayÄ± var mÄ±?
    numbers = re.findall(r'\d+[.,]?\d*', answer)
    if numbers:
        score += 15
    
    # Birim var mÄ±? (â‚º, %, kg, m, adet, gÃ¼n, saat)
    units = re.findall(r'[â‚º$â‚¬%]|(?:kg|ton|metre|mÂ²|adet|gÃ¼n|saat|hafta|ay|yÄ±l)', answer)
    if units:
        score += 10
    
    # Tablo var mÄ±?
    if '|' in answer and '-' in answer:
        score += 10
    
    # "Bilmiyorum" / "kesin deÄŸil" dÃ¼rÃ¼stlÃ¼ÄŸÃ¼
    if re.search(r'(kesin\s*bilgim\s*yok|tahmin|yaklaÅŸÄ±k|net\s*deÄŸil)', answer, re.I):
        score += 5  # DÃ¼rÃ¼stlÃ¼k Ã¶dÃ¼lÃ¼
    
    return min(100, score)


def _check_logical_consistency(answer: str) -> float:
    """MantÄ±ksal tutarlÄ±lÄ±k kontrolÃ¼."""
    score = 70.0
    
    # Ã‡eliÅŸki belirteÃ§leri
    contradictions = re.findall(
        r'(ancak|fakat|bununla birlikte|Ã¶te yandan|aksine|tam tersine)',
        answer, re.I
    )
    # Ã‡eliÅŸki normal olabilir ama Ã§ok fazlasÄ± sorun
    if len(contradictions) > 3:
        score -= 10
    
    # SonuÃ§ / tavsiye var mÄ±?
    if re.search(r'(sonuÃ§|Ã¶zet|tavsiye|Ã¶neri|sonuÃ§\s*olarak|Ã¶zetle)', answer, re.I):
        score += 15
    
    # Neden-sonuÃ§ baÄŸlantÄ±sÄ± var mÄ±?
    if re.search(r'(Ã§Ã¼nkÃ¼|nedeniyle|dolayÄ±|sonucunda|bu\s*nedenle|bu\s*yÃ¼zden)', answer, re.I):
        score += 10
    
    return min(100, score)


def _check_financial_reasoning(answer: str, mode: str) -> float:
    """Finansal akÄ±l yÃ¼rÃ¼tme kalitesi."""
    if mode == "Sohbet":
        return 80.0  # Sohbette finansal reasoning beklenmez
    
    score = 50.0
    
    # Para birimi var mÄ±?
    if re.search(r'[â‚º$â‚¬]|\d+\s*TL|milyon|milyar', answer, re.I):
        score += 20
    
    # YÃ¼zde hesabÄ± var mÄ±?
    if re.search(r'%\s*\d+|\d+\s*%', answer):
        score += 10
    
    # Maliyet/gelir/kÃ¢r kelimesi
    if re.search(r'(maliyet|gelir|kÃ¢r|zarar|tasarruf|yatÄ±rÄ±m|getiri|bÃ¼tÃ§e)', answer, re.I):
        score += 10
    
    # KarÅŸÄ±laÅŸtÄ±rma var mÄ±?
    if re.search(r'(hedef|benchmark|geÃ§en\s*(yÄ±l|ay|dÃ¶nem)|artÄ±ÅŸ|azalÄ±ÅŸ|deÄŸiÅŸim)', answer, re.I):
        score += 10
    
    return min(100, score)


def _check_risk_clarity(answer: str, mode: str) -> float:
    """Risk deÄŸerlendirmesi kalitesi."""
    if mode == "Sohbet":
        return 80.0
    
    score = 50.0
    
    # Risk kelimesi var mÄ±?
    if re.search(r'(risk|tehlike|tehdit|uyarÄ±|dikkat|sorun)', answer, re.I):
        score += 15
    
    # Risk seviyesi belirtilmiÅŸ mi?
    if re.search(r'(dÃ¼ÅŸÃ¼k|orta|yÃ¼ksek|kritik|ğŸ”´|ğŸŸ¡|ğŸŸ¢|ğŸŸ )', answer, re.I):
        score += 15
    
    # Azaltma Ã¶nerisi var mÄ±?
    if re.search(r'(Ã¶nlem|azalt|hafiflet|engellemek|Ã¶nce|tedbir)', answer, re.I):
        score += 10
    
    return min(100, score)


def _check_strategic_depth(answer: str, mode: str) -> float:
    """Stratejik derinlik kontrolÃ¼."""
    if mode in ("Sohbet", "Bilgi"):
        return 80.0
    
    score = 50.0
    
    # Zaman perspektifi var mÄ±?
    if re.search(r'(kÄ±sa\s*vade|orta\s*vade|uzun\s*vade|hemen|hafta|ay|yÄ±l)', answer, re.I):
        score += 15
    
    # Aksiyon maddesi var mÄ±?
    action_items = re.findall(r'^\s*[-â€¢âœ…\d.)\]]\s*.+', answer, re.M)
    if len(action_items) >= 3:
        score += 15
    elif len(action_items) >= 1:
        score += 8
    
    # Sorumlu / timeline var mÄ±?
    if re.search(r'(sorumlu|departman|mÃ¼dÃ¼r|ekip|tarih|deadline)', answer, re.I):
        score += 10
    
    # Alternatif / senaryo var mÄ±?
    if re.search(r'(alternatif|senaryo|seÃ§enek|plan\s*b|ihtimal)', answer, re.I):
        score += 10
    
    return min(100, score)


def _check_hallucination(answer: str, question: str) -> list[str]:
    """OlasÄ± hallucination (uydurma) tespiti."""
    issues = []
    
    # AÅŸÄ±rÄ± kesin ifadeler (genelde uydurma riski)
    overconfident = re.findall(
        r'(kesinlikle|%100|ÅŸÃ¼phesiz|tartÄ±ÅŸmasÄ±z|mutlaka.*olacak)',
        answer, re.I
    )
    if len(overconfident) > 2:
        issues.append("AÅŸÄ±rÄ± kesin ifadeler â€” uydurma riski")
    
    # TutarsÄ±z sayÄ±lar â€” aynÄ± metriÄŸin farklÄ± deÄŸerleri
    percentages = re.findall(r'(%\s*[\d.,]+|[\d.,]+\s*%)', answer)
    if len(percentages) > 8:
        # Ã‡ok fazla yÃ¼zde deÄŸeri varsa kontrol et
        values = []
        for p in percentages:
            try:
                val = float(re.search(r'[\d.,]+', p).group().replace(',', '.'))
                values.append(val)
            except:
                pass
        # 100'den bÃ¼yÃ¼k yÃ¼zde â€” hata olabilir
        for v in values:
            if v > 100 and '%' in answer:
                issues.append(f"YÃ¼zde deÄŸer %{v} > 100 â€” kontrol gerekli")
                break
    
    return issues


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# 2.5 SAYISAL DOÄRULAMA MOTORU (v4.4.0) â€” RAG Kaynak KontrolÃ¼
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def _extract_numbers(text: str) -> list[dict]:
    """Metinden sayÄ±sal deÄŸerleri ve baÄŸlamlarÄ±nÄ± Ã§Ä±kar.
    
    Returns:
        [{"value": float, "unit": str, "context": str}, ...]
    """
    patterns = [
        # Para: â‚º1.234.567 veya 1.234 TL veya $500
        (r'[â‚º$â‚¬]\s*([\d.,]+)\s*(?:milyon|milyar)?', 'para'),
        (r'([\d.,]+)\s*(?:TL|USD|EUR|â‚º|\$|â‚¬)', 'para'),
        (r'([\d.,]+)\s*(?:milyon|milyar)\s*(?:TL|USD|â‚º)?', 'para'),
        # YÃ¼zde: %15.3 veya 15.3%
        (r'%\s*([\d.,]+)', 'yÃ¼zde'),
        (r'([\d.,]+)\s*%', 'yÃ¼zde'),
        # AÄŸÄ±rlÄ±k/miktar: 500 kg, 3.2 ton
        (r'([\d.,]+)\s*(?:kg|ton|gr|gram|lt|litre|mÂ²|mÂ³|metre|adet|kiÅŸi)', 'miktar'),
        # Zaman: 15 gÃ¼n, 3 ay
        (r'([\d.,]+)\s*(?:gÃ¼n|hafta|ay|yÄ±l|saat|dakika)', 'zaman'),
        # Genel sayÄ± (baÄŸlam ile)
        (r'(?:toplam|ortalama|minimum|maksimum|yaklaÅŸÄ±k|tahmini)\s*:?\s*([\d.,]+)', 'hesaplama'),
    ]
    
    results = []
    for pattern, unit_type in patterns:
        for match in re.finditer(pattern, text, re.IGNORECASE):
            try:
                raw = match.group(1).replace('.', '').replace(',', '.')
                value = float(raw)
                # BaÄŸlam: eÅŸleÅŸmeden 40 karakter Ã¶ncesi ve sonrasÄ±
                start = max(0, match.start() - 40)
                end = min(len(text), match.end() + 40)
                context = text[start:end].strip()
                results.append({
                    "value": value,
                    "unit": unit_type,
                    "context": context,
                    "raw": match.group(0),
                })
            except (ValueError, IndexError):
                continue
    
    return results


def validate_numbers_against_source(answer: str, rag_context: str) -> dict:
    """LLM yanÄ±tÄ±ndaki sayÄ±larÄ± RAG kaynak verileriyle karÅŸÄ±laÅŸtÄ±r.
    
    Args:
        answer: LLM'in Ã¼rettiÄŸi yanÄ±t
        rag_context: RAG'dan gelen kaynak dokÃ¼manlar (birleÅŸtirilmiÅŸ metin)
    
    Returns:
        {
            "validated": bool,       # SayÄ±sal tutarlÄ±lÄ±k var mÄ±
            "match_count": int,      # EÅŸleÅŸen sayÄ± adedi
            "mismatch_count": int,   # UyuÅŸmayan sayÄ± adedi
            "fabricated_count": int,  # Kaynakta hiÃ§ olmayan sayÄ±lar
            "issues": [str],         # Sorun aÃ§Ä±klamalarÄ±
            "details": [dict],       # Detay
            "score": float,          # 0-100 doÄŸruluk skoru
        }
    """
    if not rag_context or not answer:
        return {"validated": True, "match_count": 0, "mismatch_count": 0,
                "fabricated_count": 0, "issues": [], "details": [], "score": 100}
    
    answer_numbers = _extract_numbers(answer)
    source_numbers = _extract_numbers(rag_context)
    
    if not answer_numbers:
        return {"validated": True, "match_count": 0, "mismatch_count": 0,
                "fabricated_count": 0, "issues": [], "details": [], "score": 100}
    
    # Kaynak sayÄ±larÄ± set'e Ã§evir (hÄ±zlÄ± arama iÃ§in)
    source_values = {n["value"] for n in source_numbers}
    # ToleranslÄ± eÅŸleme iÃ§in kaynak listesi
    source_list = [n["value"] for n in source_numbers]
    
    matched = 0
    mismatched = 0
    fabricated = 0
    issues = []
    details = []
    
    for ans_num in answer_numbers:
        val = ans_num["value"]
        
        # Tam eÅŸleÅŸme kontrolÃ¼
        if val in source_values:
            matched += 1
            details.append({"value": val, "status": "eÅŸleÅŸti", "raw": ans_num["raw"]})
            continue
        
        # ToleranslÄ± eÅŸleÅŸme (%5 sapma)
        found_close = False
        for src_val in source_list:
            if src_val == 0:
                continue
            diff_pct = abs(val - src_val) / abs(src_val) * 100
            if diff_pct <= 5:
                matched += 1
                found_close = True
                details.append({"value": val, "status": "yakÄ±n_eÅŸleÅŸme",
                              "source_value": src_val, "diff_pct": round(diff_pct, 1),
                              "raw": ans_num["raw"]})
                break
            elif diff_pct <= 20:
                mismatched += 1
                found_close = True
                issues.append(
                    f"SayÄ±sal sapma: yanÄ±tta {ans_num['raw']}, kaynakta {src_val} "
                    f"(fark: %{diff_pct:.0f})"
                )
                details.append({"value": val, "status": "sapma",
                              "source_value": src_val, "diff_pct": round(diff_pct, 1),
                              "raw": ans_num["raw"]})
                break
        
        if not found_close:
            # Hesaplama sonucu olabilir (toplam, ortalama vb.) â€” tolerans ver
            if ans_num["unit"] == "hesaplama":
                details.append({"value": val, "status": "hesaplama", "raw": ans_num["raw"]})
            else:
                fabricated += 1
                details.append({"value": val, "status": "kaynakta_yok", "raw": ans_num["raw"]})
    
    # Ã‡ok fazla uydurma varsa uyar
    total = matched + mismatched + fabricated
    if total == 0:
        score = 100
    else:
        score = max(0, (matched / total) * 100 - fabricated * 5 - mismatched * 10)
    
    if fabricated > 2:
        issues.append(f"âš ï¸ {fabricated} sayÄ±sal deÄŸer kaynakta bulunamadÄ± â€” uydurma riski")
    if mismatched > 1:
        issues.append(f"âš ï¸ {mismatched} sayÄ±sal deÄŸerde Ã¶nemli sapma tespit edildi")
    
    return {
        "validated": len(issues) == 0,
        "match_count": matched,
        "mismatch_count": mismatched,
        "fabricated_count": fabricated,
        "issues": issues,
        "details": details,
        "score": round(score, 1),
    }


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# 3. LLM Ä°LE DERÄ°N DEÄERLENDÄ°RME (opsiyonel, aÄŸÄ±r analiz)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

REFLECTION_PROMPT = """Sen bir kalite kontrol uzmanÄ±sÄ±n. AÅŸaÄŸÄ±daki AI yanÄ±tÄ±nÄ± deÄŸerlendir.

## KullanÄ±cÄ± Sorusu:
{question}

## AI YanÄ±tÄ±:
{answer}

## DeÄŸerlendirme Kriterleri (her birini 0-100 puanla):
1. **Veri DoÄŸruluÄŸu**: SayÄ±lar tutarlÄ± mÄ±, birimler doÄŸru mu?
2. **MantÄ±ksal TutarlÄ±lÄ±k**: Ã‡eliÅŸki var mÄ±, neden-sonuÃ§ doÄŸru mu?
3. **Finansal AkÄ±l YÃ¼rÃ¼tme**: Mali etki hesaplanmÄ±ÅŸ mÄ±?
4. **Risk NetliÄŸi**: Riskler belirlenmiÅŸ ve seviyelendirilmiÅŸ mi?
5. **Stratejik Derinlik**: KÄ±sa/orta/uzun vade Ã¶neriler var mÄ±?

## YanÄ±tÄ±nÄ± SADECE bu JSON formatÄ±nda ver:
```json
{{
  "data_accuracy": <0-100>,
  "logical_consistency": <0-100>,
  "financial_reasoning": <0-100>,
  "risk_clarity": <0-100>,
  "strategic_depth": <0-100>,
  "overall_confidence": <0-100>,
  "issues": ["sorun1", "sorun2"],
  "improvement_suggestions": ["Ã¶neri1", "Ã¶neri2"]
}}
```"""


RETRY_ENHANCEMENT_PROMPT = """Ã–nceki yanÄ±tÄ±n kalite deÄŸerlendirmesinde dÃ¼ÅŸÃ¼k puan aldÄ±.

## Sorunlar:
{issues}

## Ä°yileÅŸtirme Ã–nerileri:
{suggestions}

LÃ¼tfen yanÄ±tÄ±nÄ± ÅŸu kriterlere gÃ¶re iyileÅŸtir:
- Somut sayÄ±sal veriler ekle (â‚º, %, birim)
- Finansal etki hesabÄ± yap
- Risk seviyelerini belirt (DÃ¼ÅŸÃ¼k/Orta/YÃ¼ksek/Kritik)
- KÄ±sa/Orta/Uzun vade Ã¶neriler sun
- Best Case / Expected Case / Worst Case senaryolarÄ±nÄ± deÄŸerlendir

## Orijinal Soru:
{question}

YanÄ±tÄ±nÄ± iyileÅŸtirilmiÅŸ haliyle yeniden yaz:"""


def build_retry_prompt(question: str, evaluation: dict) -> str:
    """DÃ¼ÅŸÃ¼k kaliteli yanÄ±t iÃ§in iyileÅŸtirme prompt'u oluÅŸtur."""
    issues_text = "\n".join(f"- {i}" for i in evaluation.get("issues", []))
    suggestions_text = "\n".join(f"- {s}" for s in evaluation.get("suggestions", []))
    
    return RETRY_ENHANCEMENT_PROMPT.format(
        issues=issues_text or "- Genel kalite yetersiz",
        suggestions=suggestions_text or "- Daha detaylÄ± ve yapÄ±landÄ±rÄ±lmÄ±ÅŸ yanÄ±t ver",
        question=question,
    )


SELF_CORRECTION_PROMPT = """AÅŸaÄŸÄ±daki yanÄ±tÄ±nÄ± gÃ¶zden geÃ§ir ve iyileÅŸtir.

## Orijinal Soru:
{question}

## Mevcut YanÄ±tÄ±n:
{current_answer}

## Kalite DeÄŸerlendirmesi (GÃ¼ven: %{confidence}):
{evaluation_summary}

## GÃ¶rev:
1. YanÄ±tÄ±ndaki eksikleri ve hatalarÄ± tespit et
2. Somut veriler, sayÄ±lar ve Ã¶rneklerle zenginleÅŸtir
3. MantÄ±ksal tutarlÄ±lÄ±ÄŸÄ± kontrol et
4. YapÄ±sal netliÄŸi artÄ±r (baÅŸlÄ±klar, listeler, tablolar)

DÃ¼zeltilmiÅŸ ve iyileÅŸtirilmiÅŸ yanÄ±tÄ± yaz:"""


def build_self_correction_prompt(question: str, current_answer: str, evaluation: dict) -> str:
    """Self-correction dÃ¶ngÃ¼sÃ¼ iÃ§in prompt oluÅŸtur.
    
    Normal retry'dan farkÄ±: Mevcut yanÄ±tÄ± da gÃ¶sterir ve Ã¼zerine dÃ¼zeltme ister.
    """
    eval_summary = []
    for criterion, score in evaluation.get("criteria_scores", {}).items():
        eval_summary.append(f"- {criterion}: {score}/100")
    if evaluation.get("issues"):
        eval_summary.extend(f"- âš ï¸ {i}" for i in evaluation["issues"])
    if evaluation.get("suggestions"):
        eval_summary.extend(f"- ğŸ’¡ {s}" for s in evaluation["suggestions"])
    
    return SELF_CORRECTION_PROMPT.format(
        question=question,
        current_answer=current_answer[:2000],  # Token limiti iÃ§in kÄ±salt
        confidence=evaluation.get("confidence", 0),
        evaluation_summary="\n".join(eval_summary),
    )


async def self_correction_loop(
    question: str,
    initial_answer: str,
    mode: str,
    llm_generate,
    system_prompt: str = "",
    chat_history: list = None,
    max_rounds: int = None,
) -> dict:
    """Ä°teratif self-correction dÃ¶ngÃ¼sÃ¼.
    
    LLM Ã§Ä±ktÄ±sÄ±nÄ± deÄŸerlendirir, dÃ¼ÅŸÃ¼kse dÃ¼zeltme ister, en iyi versiyonu dÃ¶ndÃ¼rÃ¼r.
    
    Args:
        question: KullanÄ±cÄ± sorusu
        initial_answer: Ä°lk LLM yanÄ±tÄ±
        mode: YanÄ±t modu (Sohbet, Analiz, Rapor)
        llm_generate: LLM generate fonksiyonu (async)
        system_prompt: Sistem prompt'u
        chat_history: Chat geÃ§miÅŸi
        max_rounds: Maksimum dÃ¼zeltme turu
    
    Returns:
        {
            "answer": str,           # En iyi yanÄ±t
            "confidence": float,     # 0-100
            "rounds": int,           # KaÃ§ tur Ã§alÄ±ÅŸtÄ±
            "improved": bool,        # Ä°yileÅŸtirme oldu mu
            "evaluation": dict,      # Son deÄŸerlendirme
        }
    """
    if max_rounds is None:
        max_rounds = MAX_RETRY_COUNT
    
    best_answer = initial_answer
    best_confidence = 0
    best_evaluation = {}
    rounds = 0
    
    current_answer = initial_answer
    
    for i in range(max_rounds + 1):  # +1 Ã§Ã¼nkÃ¼ ilk deÄŸerlendirme de dahil
        # DeÄŸerlendir
        evaluation = quick_evaluate(current_answer, question, mode)
        confidence = evaluation.get("confidence", 0)
        rounds = i
        
        # En iyi sonucu takip et
        if confidence > best_confidence:
            best_confidence = confidence
            best_answer = current_answer
            best_evaluation = evaluation
        
        # Yeterli kalite â†’ dÃ¶ngÃ¼yÃ¼ kÄ±r
        if confidence >= AUTO_REANALYZE_THRESHOLD or not evaluation.get("should_retry"):
            break
        
        # Son tur â†’ retry yapma
        if i >= max_rounds:
            break
        
        # Self-correction prompt oluÅŸtur
        try:
            if i == 0:
                # Ä°lk retry â€” standart retry prompt
                correction_prompt = build_retry_prompt(question, evaluation)
            else:
                # Sonraki turlar â€” self-correction (mevcut yanÄ±tÄ± gÃ¶stererek)
                correction_prompt = build_self_correction_prompt(
                    question, current_answer, evaluation
                )
            
            corrected = await llm_generate(
                prompt=correction_prompt,
                system_prompt=system_prompt,
                temperature=max(0.1, 0.3 - i * 0.1),  # Her turda daha deterministik
                max_tokens=800,
                history=chat_history,
            )
            
            if corrected and len(corrected) > len(current_answer) * 0.3:
                current_answer = corrected
                logger.info("self_correction_round", round=i+1, 
                           prev_confidence=confidence)
        except Exception as e:
            logger.warning("self_correction_error", round=i+1, error=str(e))
            break
    
    improved = best_confidence > quick_evaluate(initial_answer, question, mode).get("confidence", 0)
    
    logger.info("self_correction_done", rounds=rounds, 
                final_confidence=best_confidence, improved=improved)
    
    return {
        "answer": best_answer,
        "confidence": best_confidence,
        "rounds": rounds,
        "improved": improved,
        "evaluation": best_evaluation,
    }


def format_confidence_badge(confidence: float) -> str:
    """Confidence deÄŸerini gÃ¶rsel badge'e Ã§evir."""
    if confidence >= 90:
        return f"ğŸŸ¢ GÃ¼ven: %{confidence:.0f}"
    elif confidence >= 75:
        return f"ğŸ”µ GÃ¼ven: %{confidence:.0f}"
    elif confidence >= 60:
        return f"ğŸŸ¡ GÃ¼ven: %{confidence:.0f}"
    else:
        return f"ğŸ”´ GÃ¼ven: %{confidence:.0f}"


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# 4. REFLECTION SONUCU FORMAT
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def format_reflection_footer(evaluation: dict, show_details: bool = False) -> str:
    """YanÄ±t altÄ±na reflection bilgisi ekle."""
    confidence = evaluation.get("confidence", 0)
    badge = format_confidence_badge(confidence)
    
    footer = f"\n\n---\n{badge}"
    
    if show_details and evaluation.get("criteria_scores"):
        footer += "\n<details><summary>ğŸ“Š Kalite DetayÄ±</summary>\n\n"
        for criterion, score in evaluation["criteria_scores"].items():
            bar = "â–ˆ" * int(score / 10) + "â–‘" * (10 - int(score / 10))
            footer += f"- {criterion}: {bar} {score:.0f}/100\n"
        footer += "\n</details>"
    
    if evaluation.get("issues"):
        footer += f"\nâš ï¸ {len(evaluation['issues'])} iyileÅŸtirme notu"
    
    return footer
