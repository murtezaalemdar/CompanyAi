"""LLM (Qwen2.5) Fine-Tune Pipeline â€” LoRA/QLoRA

Tekstil sektÃ¶rÃ¼ konuÅŸma geÃ§miÅŸlerinden ve domain verilerinden
QLoRA fine-tune veri seti hazÄ±rlar ve Ollama Modelfile oluÅŸturur.

KullanÄ±m:
    python -m app.scripts.finetune_llm --extract      # KonuÅŸmalardan eÄŸitim verisi Ã§Ä±kar
    python -m app.scripts.finetune_llm --prepare       # SektÃ¶r eÄŸitim seti hazÄ±rla
    python -m app.scripts.finetune_llm --modelfile     # Ollama Modelfile oluÅŸtur
    python -m app.scripts.finetune_llm --export-gguf   # Unsloth ile GGUF export script Ã¼ret

Gereksinimler (eÄŸitim iÃ§in):
    pip install unsloth datasets transformers trl peft
"""

import os
import json
import argparse
import re
from pathlib import Path
from datetime import datetime
from typing import List, Dict

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# 1. TEKSTÄ°L SEKTÃ–RÃœ EÄÄ°TÄ°M VERÄ°SÄ°
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

TEXTILE_QA_DATASET = [
    # â”€â”€ Fire / AtÄ±k YÃ¶netimi â”€â”€
    {
        "instruction": "Fire oranÄ± %4.2 olan bir tekstil fabrikasÄ± iÃ§in analiz yap.",
        "input": "",
        "output": """## Fire OranÄ± Analizi

**Mevcut Durum**: Fire oranÄ± %4.2 â€” Kabul Edilebilir seviyede ancak iyileÅŸtirme potansiyeli var.

### Benchmark KarÅŸÄ±laÅŸtÄ±rmasÄ±
| Seviye | AralÄ±k | Durum |
|--------|--------|-------|
| ğŸŸ¢ Ä°yi | <%2 | â€” |
| ğŸŸ¡ Kabul Edilebilir | %2-5 | â† Sizin konumunuz |
| ğŸŸ  YÃ¼ksek | %5-8 | â€” |
| ğŸ”´ Kritik | >%8 | â€” |

### Fire TÃ¼rÃ¼ DaÄŸÄ±lÄ±mÄ± (OlasÄ±)
- **Kesim firesi**: ~%45 (en bÃ¼yÃ¼k kaynak)
- **Dokuma hatasÄ±**: ~%25
- **Boyama hatasÄ±**: ~%20
- **DiÄŸer**: ~%10

### Maliyet Etkisi
AylÄ±k 100 ton Ã¼retimde:
- Fire miktarÄ±: 4.2 ton/ay
- Tahmini kayÄ±p: ~â‚º210,000/ay (kg baÅŸÄ± â‚º50)
- YÄ±llÄ±k kayÄ±p: ~â‚º2,520,000

### Aksiyon PlanÄ±
1. **KÄ±sa vade (1 ay)**: Pareto analizi â€” en bÃ¼yÃ¼k fire kaynaÄŸÄ±nÄ± belirle
2. **Orta vade (3 ay)**: Kesim optimizasyonu ve nesting yazÄ±lÄ±mÄ±
3. **Uzun vade (6 ay)**: AI destekli kalite kontrol sistemi

**Hedef**: %4.2 â†’ %2.5 (6 ayda %40 azalma)
Tahmini tasarruf: â‚º850,000/yÄ±l"""
    },
    
    # â”€â”€ OEE Analizi â”€â”€
    {
        "instruction": "Dokuma bÃ¶lÃ¼mÃ¼ OEE deÄŸerlendirmesi yap. KullanÄ±labilirlik %88, performans %75, kalite %96.",
        "input": "",
        "output": """## OEE Analizi â€” Dokuma BÃ¶lÃ¼mÃ¼

### Hesaplama
OEE = KullanÄ±labilirlik Ã— Performans Ã— Kalite
OEE = %88 Ã— %75 Ã— %96 = **%63.4**

### Seviye: ğŸŸ  Orta
DÃ¼nya sÄ±nÄ±fÄ± OEE >%85, sektÃ¶r ortalamasÄ± %65-75 arasÄ±ndadÄ±r.

### DarboÄŸaz Analizi
| FaktÃ¶r | DeÄŸer | Benchmark | Durum |
|--------|-------|-----------|-------|
| KullanÄ±labilirlik | %88 | >%90 | ğŸŸ¡ YakÄ±n |
| **Performans** | **%75** | >%95 | ğŸ”´ **DARBOÄAZ** |
| Kalite | %96 | >%99 | ğŸŸ¡ Ä°yi |

### Performans dÃ¼ÅŸÃ¼klÃ¼ÄŸÃ¼nÃ¼n olasÄ± nedenleri
1. **HÄ±z kayÄ±plarÄ±**: Tezgahlar optimum hÄ±zÄ±n altÄ±nda Ã§alÄ±ÅŸÄ±yor
2. **Mikro duruÅŸlar**: KayÄ±t dÄ±ÅŸÄ± kÄ±sa sÃ¼reli duraksamalar
3. **Ã‡Ã¶zgÃ¼ kopmasÄ±**: AtkÄ±/Ã§Ã¶zgÃ¼ kopma kaynaklÄ± yavaÅŸlama

### Ä°yileÅŸtirme SenaryolarÄ±
| Senaryo | Performans | OEE | Ãœretim ArtÄ±ÅŸÄ± |
|---------|-----------|-----|--------------|
| Mevcut | %75 | %63.4 | â€” |
| Performans %85 | %85 | %71.8 | +%13.3 |
| Performans %90 | %90 | %76.0 | +%19.9 |

### Aksiyon Ã–nerileri
- **Hemen**: Tezgah bazlÄ± hÄ±z analizi, yavaÅŸ makinelerin bakÄ±mÄ±
- **1 ay**: Mikro duruÅŸ kayÄ±t sistemi kurulumu
- **3 ay**: Predictive maintenance baÅŸlangÄ±cÄ±"""
    },
    
    # â”€â”€ Maliyet Analizi â”€â”€
    {
        "instruction": "Hammadde maliyeti son Ã§eyrekte %18 arttÄ±. Etki analizi yap.",
        "input": "",
        "output": """## Hammadde Maliyet ArtÄ±ÅŸÄ± Etki Analizi

### Mevcut Durum
- Hammadde maliyet artÄ±ÅŸÄ±: **%18** (son Ã§eyrek)
- SektÃ¶r ortalamasÄ± artÄ±ÅŸ: %8-12

âš ï¸ **Risk Seviyesi: YÃœKSEK** â€” SektÃ¶r ortalamasÄ±nÄ±n Ã¼zerinde maliyet artÄ±ÅŸÄ±

### Finansal Etki (AylÄ±k â‚º10M ciro varsayÄ±mÄ±)
| Kalem | Ã–nceki | GÃ¼ncel | DeÄŸiÅŸim |
|-------|--------|--------|---------|
| Hammadde maliyeti | â‚º4,000,000 | â‚º4,720,000 | +â‚º720,000 |
| BrÃ¼t kÃ¢r | â‚º2,500,000 | â‚º1,780,000 | -â‚º720,000 |
| BrÃ¼t kÃ¢r marjÄ± | %25.0 | %17.8 | -7.2 puan |

### Risk FaktÃ¶rleri
- ğŸ”´ **KÃ¢r marjÄ± erimesi**: 7.2 puanlÄ±k dÃ¼ÅŸÃ¼ÅŸ sÃ¼rdÃ¼rÃ¼lebilir deÄŸil
- ğŸŸ¡ **Rekabet dezavantajÄ±**: Fiyat artÄ±ÅŸÄ± yapÄ±lamazsa pazar kaybÄ±
- ğŸŸ¡ **Nakit akÄ±ÅŸÄ±**: Artan hammadde stok maliyeti

### Strateji Ã–nerileri
1. **Fiyat ayarlamasÄ±**: MÃ¼ÅŸteri fiyatlarÄ±na %8-10 zam (kademeli)
2. **Alternatif tedarik**: En az 2 yeni tedarikÃ§i deÄŸerlendirmesi
3. **Stok optimizasyonu**: 45 gÃ¼nlÃ¼k stoktan 30 gÃ¼ne dÃ¼ÅŸÃ¼r
4. **ÃœrÃ¼n karmasÄ±**: YÃ¼ksek marjlÄ± Ã¼rÃ¼nlere yÃ¶nel
5. **Verimlilik**: Fire oranÄ±nÄ± %1 dÃ¼ÅŸÃ¼rerek â‚º100K/ay tasarruf

### Senaryo Tablosu
| Senaryo | KÃ¢r MarjÄ± | Aksiyon |
|---------|----------|---------|
| ğŸŸ¢ Best Case | %22 | Fiyat artÄ±ÅŸÄ± + verimlilik |
| ğŸŸ¡ Expected | %19 | KÄ±smen fiyat artÄ±ÅŸÄ± |
| ğŸ”´ Worst Case | %15 | HiÃ§bir aksiyon yok |"""
    },
    
    # â”€â”€ Risk DeÄŸerlendirmesi â”€â”€
    {
        "instruction": "Tedarik zinciri risk deÄŸerlendirmesi yap.",
        "input": "",
        "output": """## Tedarik Zinciri Risk DeÄŸerlendirmesi

### Risk Matrisi
| Risk | OlasÄ±lÄ±k | Etki | Skor | Seviye |
|------|----------|------|------|--------|
| TedarikÃ§i iflasÄ± | 2 | 5 | 10 | ğŸŸ¡ Orta |
| Hammadde fiyat ÅŸoku | 4 | 4 | 16 | ğŸŸ  YÃ¼ksek |
| Lojistik gecikme | 3 | 3 | 9 | ğŸŸ¡ Orta |
| Kalite sapmasÄ± | 3 | 4 | 12 | ğŸŸ  YÃ¼ksek |
| DÃ¶viz kuru dalgalanmasÄ± | 4 | 3 | 12 | ğŸŸ  YÃ¼ksek |

### Kritik Riskler ve Aksiyonlar

**1. Hammadde Fiyat Åoku (Skor: 16)**
- Risk: Ä°plik/kumaÅŸ fiyatlarÄ±nda ani artÄ±ÅŸ
- Azaltma: Vadeli kontratlar, minimum 2 tedarikÃ§i
- SÃ¼re: Hemen baÅŸla - Sorumlu: SatÄ±nalma MÃ¼dÃ¼rÃ¼

**2. Kalite SapmasÄ± (Skor: 12)**
- Risk: Gelen hammaddede kalite dÃ¼ÅŸÃ¼ÅŸÃ¼
- Azaltma: GiriÅŸ kalite kontrol sÄ±kÄ±laÅŸtÄ±r, tedarikÃ§i audit
- SÃ¼re: 2 hafta - Sorumlu: Kalite MÃ¼dÃ¼rÃ¼

**3. DÃ¶viz Kuru (Skor: 12)**
- Risk: TL deÄŸer kaybÄ±yla ithal girdi maliyeti artÄ±ÅŸÄ±
- Azaltma: DoÄŸal hedge, yerli tedarikÃ§i geliÅŸtirme
- SÃ¼re: SÃ¼rekli - Sorumlu: Finans MÃ¼dÃ¼rÃ¼

### Toplam Risk Skoru: **59/125** â€” Orta-YÃ¼ksek
Aksiyon planÄ± uygulanmazsa 3 ay iÃ§inde finansal etki: **â‚º500K-1.2M**"""
    },
    
    # â”€â”€ Sohbet / TÃ¼rkÃ§e doÄŸal dil â”€â”€
    {
        "instruction": "Merhaba, nasÄ±lsÄ±n?",
        "input": "",
        "output": "Merhaba! Ben CompanyAI, ÅŸirketinizin yapay zeka asistanÄ±yÄ±m. Ä°yi bir gÃ¼n geÃ§iriyorum, size nasÄ±l yardÄ±mcÄ± olabilirim? Ãœretim verileri, maliyet analizi, risk deÄŸerlendirmesi veya herhangi bir konuda sorularÄ±nÄ±zÄ± yanÄ±tlamaya hazÄ±rÄ±m."
    },
    {
        "instruction": "Beni tanÄ±yor musun?",
        "input": "",
        "output": "Elbette! Sistemdeki kullanÄ±cÄ± profilinizi ve Ã¶nceki konuÅŸmalarÄ±mÄ±zÄ± hatÄ±rlÄ±yorum. Her konuÅŸmamÄ±zda sizin iÃ§in daha kiÅŸiselleÅŸtirilmiÅŸ yanÄ±tlar Ã¼retebiliyorum. DepartmanÄ±nÄ±za ve ilgi alanlarÄ±nÄ±za gÃ¶re analizlerimi Ã¶zelleÅŸtiriyorum."
    },
    
    # â”€â”€ KPI Yorumlama â”€â”€
    {
        "instruction": "Personel devir hÄ±zÄ± %22. Bu ne anlama geliyor?",
        "input": "",
        "output": """## Personel Devir HÄ±zÄ± Analizi

**Mevcut DeÄŸer**: %22 â€” ğŸŸ  **YÃ¼ksek**

### Benchmark KarÅŸÄ±laÅŸtÄ±rmasÄ±
- Tekstil sektÃ¶rÃ¼ ortalamasÄ±: %15-20
- Ä°yi seviye: <%12
- Sizin deÄŸeriniz sektÃ¶r ortalamasÄ±nÄ±n Ã¼zerinde

### Maliyet Etkisi
Her ayrÄ±lan Ã§alÄ±ÅŸanÄ±n ortalama maliyeti = 3-6 aylÄ±k maaÅŸ
- 100 kiÅŸilik fabrikada yÄ±lda ~22 kiÅŸi ayrÄ±lÄ±yor
- Tahmini yÄ±llÄ±k maliyet: â‚º600,000-1,200,000

### OlasÄ± Nedenler
1. Ãœcret politikasÄ± rekabetÃ§i deÄŸil
2. Ã‡alÄ±ÅŸma koÅŸullarÄ± (vardiya sistemi, fiziksel ortam)
3. Kariyer geliÅŸim fÄ±rsatÄ± eksikliÄŸi
4. YÃ¶netim/iletiÅŸim sorunlarÄ±

### Ã–neriler
- **Hemen**: Ã‡Ä±kÄ±ÅŸ mÃ¼lakatÄ± analizi â€” gerÃ§ek nedenleri belirle
- **1 ay**: Ãœcret benchmarking Ã§alÄ±ÅŸmasÄ±
- **3 ay**: Ã‡alÄ±ÅŸan memnuniyet anketi + aksiyon planÄ±
- **Hedef**: %22 â†’ %15 (12 ayda)"""
    },
]


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# 2. KONUÅMA GEÃ‡MÄ°ÅÄ°NDEN VERÄ° Ã‡IKARMA
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def extract_from_conversations(db_url: str = None) -> List[Dict]:
    """PostgreSQL konuÅŸma geÃ§miÅŸinden eÄŸitim verisi Ã§Ä±kar.
    
    YÃ¼ksek kaliteli Q&A Ã§iftlerini seÃ§er:
    - Confidence > 70%
    - YanÄ±t uzunluÄŸu > 100 karakter
    - Ä°ÅŸ/analiz intent'li sorular
    """
    dataset = []
    
    try:
        import psycopg2
        conn_url = db_url or os.environ.get(
            "DATABASE_URL", 
            "postgresql://companyai:companyai123@localhost:5432/companyai"
        )
        conn = psycopg2.connect(conn_url)
        cur = conn.cursor()
        
        # YÃ¼ksek kaliteli konuÅŸmalarÄ± Ã§ek
        cur.execute("""
            SELECT question, answer, confidence, mode, intent
            FROM conversations 
            WHERE confidence > 0.70 
            AND length(answer) > 100
            AND intent IN ('iÅŸ', 'bilgi')
            ORDER BY created_at DESC
            LIMIT 500
        """)
        
        rows = cur.fetchall()
        for q, a, conf, mode, intent in rows:
            # Temizleme
            clean_q = q.strip()
            clean_a = a.strip()
            
            # Confidence badge'i temizle
            clean_a = re.sub(r'\n---\n[ğŸŸ¢ğŸ”µğŸŸ¡ğŸ”´].*$', '', clean_a, flags=re.MULTILINE)
            
            if len(clean_q) > 10 and len(clean_a) > 50:
                dataset.append({
                    "instruction": clean_q,
                    "input": "",
                    "output": clean_a,
                    "metadata": {"confidence": conf, "mode": mode, "intent": intent},
                })
        
        cur.close()
        conn.close()
        print(f"âœ… PostgreSQL'den {len(dataset)} konuÅŸma Ã§Ä±karÄ±ldÄ±")
        
    except Exception as e:
        print(f"âš ï¸ PostgreSQL baÄŸlantÄ± hatasÄ±: {e}")
        print("   Sunucuda Ã§alÄ±ÅŸtÄ±rÄ±n veya DATABASE_URL env ayarlayÄ±n")
    
    return dataset


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# 3. EÄÄ°TÄ°M VERÄ°SÄ° HAZIRLAMA
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def prepare_training_data(output_dir: str = "data/llm_training") -> str:
    """TÃ¼m kaynaklardan eÄŸitim verisini birleÅŸtir ve formatla."""
    Path(output_dir).mkdir(parents=True, exist_ok=True)
    
    all_data = []
    
    # 1. Sabit tekstil veri seti
    all_data.extend(TEXTILE_QA_DATASET)
    print(f"  ğŸ“ Tekstil veri seti: {len(TEXTILE_QA_DATASET)} Ã¶rnek")
    
    # 2. KonuÅŸma geÃ§miÅŸi
    conv_data = extract_from_conversations()
    all_data.extend(conv_data)
    print(f"  ğŸ’¬ KonuÅŸma geÃ§miÅŸi: {len(conv_data)} Ã¶rnek")
    
    # 3. Alpaca formatÄ±na Ã§evir (Qwen2.5 uyumlu)
    alpaca_data = []
    for item in all_data:
        alpaca_data.append({
            "instruction": item["instruction"],
            "input": item.get("input", ""),
            "output": item["output"],
        })
    
    # Train/Eval split
    import random
    random.shuffle(alpaca_data)
    split_idx = int(len(alpaca_data) * 0.9)
    train = alpaca_data[:split_idx]
    eval_data = alpaca_data[split_idx:]
    
    # Kaydet
    train_path = os.path.join(output_dir, "train.json")
    eval_path = os.path.join(output_dir, "eval.json")
    
    with open(train_path, "w", encoding="utf-8") as f:
        json.dump(train, f, ensure_ascii=False, indent=2)
    
    with open(eval_path, "w", encoding="utf-8") as f:
        json.dump(eval_data, f, ensure_ascii=False, indent=2)
    
    print(f"\nâœ… EÄŸitim verisi hazÄ±r:")
    print(f"   Train: {len(train)} Ã¶rnek â†’ {train_path}")
    print(f"   Eval:  {len(eval_data)} Ã¶rnek â†’ {eval_path}")
    
    return train_path


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# 4. UNSLOTH QLoRA EÄÄ°TÄ°M SCRÄ°PTÄ°
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

UNSLOTH_TRAINING_SCRIPT = '''#!/usr/bin/env python3
"""Qwen2.5 QLoRA Fine-Tune Script (Unsloth ile)

Bu script'i GPU olan makinede Ã§alÄ±ÅŸtÄ±rÄ±n.
Gereksinimler: pip install "unsloth[cu121-torch240]" datasets

Kaynak: data/llm_training/train.json
Ã‡Ä±ktÄ±: models/qwen25-textile-lora/
"""

from unsloth import FastLanguageModel
from datasets import load_dataset
from trl import SFTTrainer
from transformers import TrainingArguments
import torch

# â”€â”€â”€ 1. Model YÃ¼kle â”€â”€â”€
model, tokenizer = FastLanguageModel.from_pretrained(
    model_name="unsloth/Qwen2.5-7B-Instruct-bnb-4bit",  # 4bit quantized
    max_seq_length=2048,
    dtype=None,  # Auto-detect
    load_in_4bit=True,
)

# â”€â”€â”€ 2. LoRA AdaptÃ¶r Ekle â”€â”€â”€
model = FastLanguageModel.get_peft_model(
    model,
    r=16,        # LoRA rank
    target_modules=["q_proj", "k_proj", "v_proj", "o_proj",
                     "gate_proj", "up_proj", "down_proj"],
    lora_alpha=16,
    lora_dropout=0,
    bias="none",
    use_gradient_checkpointing="unsloth",
)

# â”€â”€â”€ 3. Veri Seti â”€â”€â”€
alpaca_prompt = """### Instruction:
{instruction}

### Input:
{input}

### Response:
{output}"""

def formatting_prompts_func(examples):
    texts = []
    for i in range(len(examples["instruction"])):
        text = alpaca_prompt.format(
            instruction=examples["instruction"][i],
            input=examples["input"][i],
            output=examples["output"][i],
        )
        texts.append(text + tokenizer.eos_token)
    return {"text": texts}

dataset = load_dataset("json", data_files="data/llm_training/train.json", split="train")
dataset = dataset.map(formatting_prompts_func, batched=True)

# â”€â”€â”€ 4. EÄŸitim â”€â”€â”€
trainer = SFTTrainer(
    model=model,
    tokenizer=tokenizer,
    train_dataset=dataset,
    dataset_text_field="text",
    max_seq_length=2048,
    args=TrainingArguments(
        per_device_train_batch_size=2,
        gradient_accumulation_steps=4,
        warmup_steps=5,
        num_train_epochs=3,
        learning_rate=2e-4,
        fp16=not torch.cuda.is_bf16_supported(),
        bf16=torch.cuda.is_bf16_supported(),
        logging_steps=1,
        output_dir="models/qwen25-textile-lora",
        save_strategy="epoch",
    ),
)

trainer.train()

# â”€â”€â”€ 5. GGUF Export â”€â”€â”€
print("\\nğŸ“¦ GGUF export baÅŸlatÄ±lÄ±yor...")
model.save_pretrained_gguf(
    "models/qwen25-textile-gguf",
    tokenizer,
    quantization_method="q4_k_m",  # 4-bit quantization
)
print("âœ… GGUF model hazÄ±r: models/qwen25-textile-gguf/")
print("   Ollama'ya yÃ¼klemek iÃ§in: ollama create companyai-textile -f Modelfile")
'''


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# 5. OLLAMA MODELFILE
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def generate_modelfile(gguf_path: str = "models/qwen25-textile-gguf/unsloth.Q4_K_M.gguf"):
    """Ollama Modelfile oluÅŸtur."""
    modelfile = f"""# CompanyAI Tekstil Fine-Tuned Model
# Ollama'ya yÃ¼kle: ollama create companyai-textile -f Modelfile

FROM {gguf_path}

# Parametreler
PARAMETER temperature 0.4
PARAMETER top_p 0.9
PARAMETER top_k 40
PARAMETER repeat_penalty 1.1
PARAMETER num_ctx 4096

# Sistem prompt'u
SYSTEM \"\"\"Sen CompanyAI, TÃ¼rk tekstil sektÃ¶rÃ¼ne uzmanlaÅŸmÄ±ÅŸ kurumsal yapay zeka asistanÄ±sÄ±n.

GÃ¶revlerin:
- Ãœretim verisi analizi (OEE, fire, verimlilik)
- Maliyet ve finansal etki hesaplama
- Risk deÄŸerlendirmesi ve yÃ¶netimi
- KPI yorumlama ve benchmark karÅŸÄ±laÅŸtÄ±rma
- Stratejik Ã¶neriler ve aksiyon planlarÄ±

Kurallar:
- Her zaman somut sayÄ±sal veriler kullan
- TÃ¼rk LirasÄ± (â‚º) cinsinden maliyet hesapla
- SektÃ¶rel benchmark'larla karÅŸÄ±laÅŸtÄ±r
- KÄ±sa, orta ve uzun vadeli Ã¶neriler sun
- Risk seviyelerini belirt (DÃ¼ÅŸÃ¼k/Orta/YÃ¼ksek/Kritik)
- Tablo ve liste formatÄ± kullan
- TÃ¼rkÃ§e yanÄ±t ver
\"\"\"

# Template â€” Qwen2.5 chat formatÄ±
TEMPLATE \"\"\"{{{{ if .System }}}}<|im_start|>system
{{{{ .System }}}}<|im_end|>
{{{{ end }}}}{{{{ if .Prompt }}}}<|im_start|>user
{{{{ .Prompt }}}}<|im_end|>
{{{{ end }}}}<|im_start|>assistant
{{{{ .Response }}}}<|im_end|>
\"\"\"
"""
    
    modelfile_path = "Modelfile.textile"
    with open(modelfile_path, "w", encoding="utf-8") as f:
        f.write(modelfile)
    
    print(f"âœ… Ollama Modelfile oluÅŸturuldu: {modelfile_path}")
    print(f"   KullanÄ±m: ollama create companyai-textile -f {modelfile_path}")
    
    return modelfile_path


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# 6. CLI
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

if __name__ == "__main__":
    parser = argparse.ArgumentParser(description="LLM Fine-Tune Pipeline")
    parser.add_argument("--extract", action="store_true", help="KonuÅŸmalardan veri Ã§Ä±kar")
    parser.add_argument("--prepare", action="store_true", help="EÄŸitim verisi hazÄ±rla (sabit + konuÅŸma)")
    parser.add_argument("--modelfile", action="store_true", help="Ollama Modelfile oluÅŸtur")
    parser.add_argument("--export-script", action="store_true", help="Unsloth eÄŸitim script'i oluÅŸtur")
    parser.add_argument("--full", action="store_true", help="TÃ¼m adÄ±mlarÄ± Ã§alÄ±ÅŸtÄ±r")
    
    args = parser.parse_args()
    
    if args.extract:
        data = extract_from_conversations()
        if data:
            path = "data/llm_training/conversations.json"
            Path("data/llm_training").mkdir(parents=True, exist_ok=True)
            with open(path, "w", encoding="utf-8") as f:
                json.dump(data, f, ensure_ascii=False, indent=2)
            print(f"   Kaydedildi: {path}")
    
    elif args.prepare:
        prepare_training_data()
    
    elif args.modelfile:
        generate_modelfile()
    
    elif args.export_script:
        script_path = "train_qwen_lora.py"
        with open(script_path, "w", encoding="utf-8") as f:
            f.write(UNSLOTH_TRAINING_SCRIPT)
        print(f"âœ… EÄŸitim script'i oluÅŸturuldu: {script_path}")
        print(f"   GPU makinede Ã§alÄ±ÅŸtÄ±rÄ±n: python {script_path}")
    
    elif args.full:
        print("â•â•â• Tam Pipeline â•â•â•\n")
        print("1ï¸âƒ£ EÄŸitim verisi hazÄ±rlanÄ±yor...")
        prepare_training_data()
        print("\n2ï¸âƒ£ Ollama Modelfile oluÅŸturuluyor...")
        generate_modelfile()
        print("\n3ï¸âƒ£ EÄŸitim script'i oluÅŸturuluyor...")
        script_path = "train_qwen_lora.py"
        with open(script_path, "w", encoding="utf-8") as f:
            f.write(UNSLOTH_TRAINING_SCRIPT)
        print(f"   âœ… {script_path}")
        print("\nâ•â•â• Sonraki AdÄ±mlar â•â•â•")
        print("1. GPU makinede: python train_qwen_lora.py")
        print("2. GGUF dosyasÄ±nÄ± sunucuya kopyala")
        print("3. ollama create companyai-textile -f Modelfile.textile")
        print("4. app/config.py'de MODEL_NAME'i gÃ¼ncelle")
    
    else:
        parser.print_help()
